{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_pendulum import get_pendulum_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = get_pendulum_data(100)\n",
    "validation_data = get_pendulum_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = training_data['x'].shape[-1]\n",
    "params['latent_dim'] = 1\n",
    "params['model_order'] = 2\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(2*params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_x'] = 5e-4\n",
    "params['loss_weight_sindy_z'] = 5e-5\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [128,64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5000\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 22:40:42.649207: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   training loss 0.013158665969967842, (0.008050801, 0.00022505404, 10.195771, 0.996659)\n",
      "   validation loss 0.01769832707941532, (0.0083353445, 0.0006389415, 18.705967, 0.996659)\n",
      "decoder loss ratio: 0.993749, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.01232650876045227, (0.007223421, 3.6008663e-05, 10.195771, 0.52005935)\n",
      "   validation loss 0.016880638897418976, (0.007522451, 8.01487e-05, 18.705967, 0.52005935)\n",
      "decoder loss ratio: 0.896835, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.012324335053563118, (0.0072259605, 0.00033027757, 10.195771, 0.047261674)\n",
      "   validation loss 0.01686091348528862, (0.0075074094, 0.0009635908, 18.705967, 0.047261674)\n",
      "decoder loss ratio: 0.895041, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.012324738316237926, (0.0072267745, 0.0015256598, 10.195771, 5.4546865e-05)\n",
      "   validation loss 0.016857534646987915, (0.0075043375, 0.0042744474, 18.705967, 5.4546865e-05)\n",
      "decoder loss ratio: 0.894675, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.012322874739766121, (0.007224462, 0.008268642, 10.195771, 0.011362958)\n",
      "   validation loss 0.016855312511324883, (0.0075012255, 0.019812442, 18.705967, 0.011362958)\n",
      "decoder loss ratio: 0.894304, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.011119729839265347, (0.0060624015, 0.10182649, 10.102935, 0.07693154)\n",
      "   validation loss 0.016052255406975746, (0.0067214607, 0.70276505, 18.589771, 0.07693154)\n",
      "decoder loss ratio: 0.801340, decoder SINDy loss  ratio: 0.993788\n",
      "THRESHOLDING: 4 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.0077115935273468494, (0.0047022654, 0.29379982, 5.987666, 0.080453336)\n",
      "   validation loss 0.012108051218092442, (0.005380967, 1.2930363, 13.323255, 0.080453336)\n",
      "decoder loss ratio: 0.641525, decoder SINDy loss  ratio: 0.712246\n",
      "Epoch 700\n",
      "   training loss 0.004406643100082874, (0.0032250783, 0.47543252, 2.3142397, 0.067315854)\n",
      "   validation loss 0.00771406851708889, (0.0037589718, 1.1713853, 7.7917085, 0.067315854)\n",
      "decoder loss ratio: 0.448149, decoder SINDy loss  ratio: 0.416536\n",
      "Epoch 800\n",
      "   training loss 0.0021699857898056507, (0.0018272821, 0.3273791, 0.6513625, 0.06535527)\n",
      "   validation loss 0.004779529757797718, (0.0026360652, 1.0310855, 4.1825137, 0.06535527)\n",
      "decoder loss ratio: 0.314275, decoder SINDy loss  ratio: 0.223592\n",
      "Epoch 900\n",
      "   training loss 0.0007153964252211154, (0.0006279809, 0.120033495, 0.16128786, 0.07699219)\n",
      "   validation loss 0.00323869613930583, (0.0020197078, 0.80401456, 2.356035, 0.07699219)\n",
      "decoder loss ratio: 0.240792, decoder SINDy loss  ratio: 0.125951\n",
      "Epoch 1000\n",
      "   training loss 0.00011818936764029786, (9.300556e-05, 0.039093316, 0.044757314, 0.08504849)\n",
      "   validation loss 0.0022300593554973602, (0.0015238151, 0.6676207, 1.3440253, 0.08504849)\n",
      "decoder loss ratio: 0.181671, decoder SINDy loss  ratio: 0.071850\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 5.4248375818133354e-05, (3.474379e-05, 0.08213046, 0.029481756, 0.06571857)\n",
      "   validation loss 0.0016471834387630224, (0.0012052438, 0.41873214, 0.8406918, 0.06571857)\n",
      "decoder loss ratio: 0.143690, decoder SINDy loss  ratio: 0.044942\n",
      "Epoch 1200\n",
      "   training loss 3.258663127780892e-05, (1.7188018e-05, 0.05816224, 0.023698093, 0.0641457)\n",
      "   validation loss 0.001224464038386941, (0.0009197076, 0.3079817, 0.577432, 0.0641457)\n",
      "decoder loss ratio: 0.109649, decoder SINDy loss  ratio: 0.030869\n",
      "Epoch 1300\n",
      "   training loss 2.299058724020142e-05, (1.03437005e-05, 0.041793138, 0.019757729, 0.067836545)\n",
      "   validation loss 0.0009367537568323314, (0.0007125239, 0.24397554, 0.4227055, 0.067836545)\n",
      "decoder loss ratio: 0.084948, decoder SINDy loss  ratio: 0.022597\n",
      "Epoch 1400\n",
      "   training loss 1.8931908925878815e-05, (8.262047e-06, 0.032476977, 0.016681114, 0.07054555)\n",
      "   validation loss 0.0007118958164937794, (0.00054822426, 0.22212212, 0.30371997, 0.07054555)\n",
      "decoder loss ratio: 0.065360, decoder SINDy loss  ratio: 0.016237\n",
      "Epoch 1500\n",
      "   training loss 1.6734982636990026e-05, (7.4758645e-06, 0.025031032, 0.014553082, 0.07310251)\n",
      "   validation loss 0.000558840692974627, (0.00043711637, 0.18468845, 0.22351776, 0.07310251)\n",
      "decoder loss ratio: 0.052113, decoder SINDy loss  ratio: 0.011949\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 1.4882817595207598e-05, (6.7362685e-06, 0.019062152, 0.012871366, 0.075775884)\n",
      "   validation loss 0.0004582373658195138, (0.00036110758, 0.15941167, 0.17680289, 0.075775884)\n",
      "decoder loss ratio: 0.043052, decoder SINDy loss  ratio: 0.009452\n",
      "Epoch 1700\n",
      "   training loss 1.355758013232844e-05, (6.2417175e-06, 0.015234195, 0.011546687, 0.078080945)\n",
      "   validation loss 0.0003817114047706127, (0.000300557, 0.15892877, 0.14485426, 0.078080945)\n",
      "decoder loss ratio: 0.035833, decoder SINDy loss  ratio: 0.007744\n",
      "Epoch 1800\n",
      "   training loss 1.253310801985208e-05, (5.848077e-06, 0.012227685, 0.010540569, 0.080336235)\n",
      "   validation loss 0.00032609401387162507, (0.00025645702, 0.1555432, 0.12211297, 0.080336235)\n",
      "decoder loss ratio: 0.030575, decoder SINDy loss  ratio: 0.006528\n",
      "Epoch 1900\n",
      "   training loss 1.171899293694878e-05, (5.4844427e-06, 0.010082576, 0.009812055, 0.082439445)\n",
      "   validation loss 0.00028086791280657053, (0.00022079557, 0.12231073, 0.10626482, 0.082439445)\n",
      "decoder loss ratio: 0.026323, decoder SINDy loss  ratio: 0.005681\n",
      "Epoch 2000\n",
      "   training loss 1.0899372682615649e-05, (5.0321487e-06, 0.008492006, 0.009200678, 0.08422842)\n",
      "   validation loss 0.0002367777342442423, (0.00018396294, 0.09431132, 0.0945139, 0.08422842)\n",
      "decoder loss ratio: 0.021932, decoder SINDy loss  ratio: 0.005053\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 1.0228170140180737e-05, (4.6591063e-06, 0.007250358, 0.008697218, 0.08579373)\n",
      "   validation loss 0.00020065401622559875, (0.00015263552, 0.08093163, 0.08622794, 0.08579373)\n",
      "decoder loss ratio: 0.018197, decoder SINDy loss  ratio: 0.004610\n",
      "Epoch 2200\n",
      "   training loss 9.654259883973282e-06, (4.3422083e-06, 0.006227073, 0.008257178, 0.08721089)\n",
      "   validation loss 0.00017293427663389593, (0.00012852877, 0.07346336, 0.079720445, 0.08721089)\n",
      "decoder loss ratio: 0.015323, decoder SINDy loss  ratio: 0.004262\n",
      "Epoch 2300\n",
      "   training loss 9.105046046897769e-06, (4.0233754e-06, 0.0053841793, 0.007856042, 0.08844403)\n",
      "   validation loss 0.00014930468751117587, (0.0001073446, 0.080408566, 0.07411045, 0.08844403)\n",
      "decoder loss ratio: 0.012798, decoder SINDy loss  ratio: 0.003962\n",
      "Epoch 2400\n",
      "   training loss 8.568636985728517e-06, (3.708057e-06, 0.0046479637, 0.007465147, 0.08956087)\n",
      "   validation loss 0.0001263765007024631, (8.6303626e-05, 0.09617464, 0.06873705, 0.08956087)\n",
      "decoder loss ratio: 0.010289, decoder SINDy loss  ratio: 0.003675\n",
      "Epoch 2500\n",
      "   training loss 8.09790344646899e-06, (3.4294649e-06, 0.0040215473, 0.007122271, 0.090622514)\n",
      "   validation loss 0.0001045479511958547, (6.648855e-05, 0.10734493, 0.06357184, 0.090622514)\n",
      "decoder loss ratio: 0.007927, decoder SINDy loss  ratio: 0.003398\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 7.743059541098773e-06, (3.2133003e-06, 0.0035589077, 0.006871645, 0.09159911)\n",
      "   validation loss 8.545986929675564e-05, (4.965075e-05, 0.1083078, 0.05895547, 0.09159911)\n",
      "decoder loss ratio: 0.005919, decoder SINDy loss  ratio: 0.003152\n",
      "Epoch 2700\n",
      "   training loss 7.429965080518741e-06, (3.0293706e-06, 0.0032093637, 0.0066313436, 0.092445396)\n",
      "   validation loss 7.017485040705651e-05, (3.690619e-05, 0.10002405, 0.054686006, 0.092445396)\n",
      "decoder loss ratio: 0.004400, decoder SINDy loss  ratio: 0.002923\n",
      "Epoch 2800\n",
      "   training loss 7.2160960371547844e-06, (2.9074004e-06, 0.0029998876, 0.006454859, 0.09312716)\n",
      "   validation loss 5.8737983636092395e-05, (2.7967539e-05, 0.08711413, 0.05096693, 0.09312716)\n",
      "decoder loss ratio: 0.003334, decoder SINDy loss  ratio: 0.002725\n",
      "Epoch 2900\n",
      "   training loss 6.98892108630389e-06, (2.7749356e-06, 0.0028458424, 0.0062703094, 0.09365388)\n",
      "   validation loss 5.029020758229308e-05, (2.1934178e-05, 0.073225304, 0.047516447, 0.09365388)\n",
      "decoder loss ratio: 0.002615, decoder SINDy loss  ratio: 0.002540\n",
      "Epoch 3000\n",
      "   training loss 6.8001272666151635e-06, (2.6721661e-06, 0.0027776454, 0.006096629, 0.09407639)\n",
      "   validation loss 4.414299473864958e-05, (1.7985321e-05, 0.060181484, 0.04441567, 0.09407639)\n",
      "decoder loss ratio: 0.002144, decoder SINDy loss  ratio: 0.002374\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 9.320888239017222e-06, (2.5997542e-06, 0.01177491, 0.010520742, 0.08720169)\n",
      "   validation loss 4.449150583241135e-05, (1.6115837e-05, 0.05853443, 0.04915386, 0.08720169)\n",
      "decoder loss ratio: 0.001921, decoder SINDy loss  ratio: 0.002628\n",
      "Epoch 3200\n",
      "   training loss 8.012307262106333e-06, (2.259929e-06, 0.00925565, 0.008835864, 0.08716638)\n",
      "   validation loss 3.8610276533290744e-05, (1.3966901e-05, 0.04654226, 0.042889196, 0.08716638)\n",
      "decoder loss ratio: 0.001665, decoder SINDy loss  ratio: 0.002293\n",
      "Epoch 3300\n",
      "   training loss 7.484698471671436e-06, (2.1033215e-06, 0.008358321, 0.00816975, 0.08785862)\n",
      "   validation loss 3.5080469388049096e-05, (1.2497459e-05, 0.039507393, 0.03945811, 0.08785862)\n",
      "decoder loss ratio: 0.001490, decoder SINDy loss  ratio: 0.002109\n",
      "Epoch 3400\n",
      "   training loss 6.956728611839935e-06, (1.9487868e-06, 0.0074711083, 0.007498487, 0.08851429)\n",
      "   validation loss 3.201593062840402e-05, (1.1318314e-05, 0.034203492, 0.0362046, 0.08851429)\n",
      "decoder loss ratio: 0.001349, decoder SINDy loss  ratio: 0.001935\n",
      "Epoch 3500\n",
      "   training loss 6.495647994597675e-06, (1.8058996e-06, 0.0066949856, 0.006927218, 0.089138985)\n",
      "   validation loss 2.9448734494508244e-05, (1.0365109e-05, 0.030165492, 0.03336792, 0.089138985)\n",
      "decoder loss ratio: 0.001236, decoder SINDy loss  ratio: 0.001784\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 6.07363926974358e-06, (1.6723696e-06, 0.0060104774, 0.0064064423, 0.089752465)\n",
      "   validation loss 2.7241027055424638e-05, (9.561919e-06, 0.027199743, 0.030843193, 0.089752465)\n",
      "decoder loss ratio: 0.001140, decoder SINDy loss  ratio: 0.001649\n",
      "Epoch 3700\n",
      "   training loss 5.700424026144901e-06, (1.554056e-06, 0.0054076817, 0.005944961, 0.09035033)\n",
      "   validation loss 2.5386145352968015e-05, (8.917602e-06, 0.025022252, 0.028627854, 0.09035033)\n",
      "decoder loss ratio: 0.001063, decoder SINDy loss  ratio: 0.001530\n",
      "Epoch 3800\n",
      "   training loss 5.384235009842087e-06, (1.4560143e-06, 0.004888973, 0.005548945, 0.090929925)\n",
      "   validation loss 2.3806465833331458e-05, (8.374743e-06, 0.023461407, 0.026698703, 0.090929925)\n",
      "decoder loss ratio: 0.000998, decoder SINDy loss  ratio: 0.001427\n",
      "Epoch 3900\n",
      "   training loss 5.108169261802686e-06, (1.368238e-06, 0.004452658, 0.0052044527, 0.09150716)\n",
      "   validation loss 2.2435004211729392e-05, (7.893206e-06, 0.022349732, 0.025018476, 0.09150716)\n",
      "decoder loss ratio: 0.000941, decoder SINDy loss  ratio: 0.001337\n",
      "Epoch 4000\n",
      "   training loss 4.882313987764064e-06, (1.3045742e-06, 0.0040885382, 0.004905256, 0.09206853)\n",
      "   validation loss 2.1277952328091487e-05, (7.4967925e-06, 0.021625176, 0.02355843, 0.09206853)\n",
      "decoder loss ratio: 0.000894, decoder SINDy loss  ratio: 0.001259\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 4.680232905229786e-06, (1.2441767e-06, 0.0037868973, 0.0046411348, 0.09261441)\n",
      "   validation loss 2.0269208107492886e-05, (7.1446216e-06, 0.021193784, 0.022277506, 0.09261441)\n",
      "decoder loss ratio: 0.000852, decoder SINDy loss  ratio: 0.001191\n",
      "Epoch 4200\n",
      "   training loss 4.504530807025731e-06, (1.1920692e-06, 0.0035349154, 0.0044082375, 0.09315968)\n",
      "   validation loss 1.9390363377169706e-05, (6.832725e-06, 0.020990266, 0.021153057, 0.09315968)\n",
      "decoder loss ratio: 0.000815, decoder SINDy loss  ratio: 0.001131\n",
      "Epoch 4300\n",
      "   training loss 4.349523806013167e-06, (1.1459617e-06, 0.0033306498, 0.004200385, 0.09368368)\n",
      "   validation loss 1.8623928554006852e-05, (6.559212e-06, 0.020973012, 0.020158459, 0.09368368)\n",
      "decoder loss ratio: 0.000782, decoder SINDy loss  ratio: 0.001078\n",
      "Epoch 4400\n",
      "   training loss 4.212424300931161e-06, (1.1017748e-06, 0.0031592958, 0.0040218653, 0.09417516)\n",
      "   validation loss 1.7917916920850985e-05, (6.2761706e-06, 0.021084277, 0.019291563, 0.09417516)\n",
      "decoder loss ratio: 0.000748, decoder SINDy loss  ratio: 0.001031\n",
      "Epoch 4500\n",
      "   training loss 4.098276349395746e-06, (1.0695263e-06, 0.003021132, 0.0038626085, 0.094638914)\n",
      "   validation loss 1.731783959257882e-05, (6.044921e-06, 0.021299742, 0.018523084, 0.094638914)\n",
      "decoder loss ratio: 0.000721, decoder SINDy loss  ratio: 0.000990\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 3.998045485786861e-06, (1.0430056e-06, 0.002903922, 0.0037184274, 0.09506302)\n",
      "   validation loss 1.678102489677258e-05, (5.8342152e-06, 0.021564944, 0.017835867, 0.09506302)\n",
      "decoder loss ratio: 0.000696, decoder SINDy loss  ratio: 0.000953\n",
      "Epoch 4700\n",
      "   training loss 3.910364284820389e-06, (1.0144948e-06, 0.0028063778, 0.0036022752, 0.09544128)\n",
      "   validation loss 1.6285730453091674e-05, (5.6154577e-06, 0.021848362, 0.017246881, 0.09544128)\n",
      "decoder loss ratio: 0.000669, decoder SINDy loss  ratio: 0.000922\n",
      "Epoch 4800\n",
      "   training loss 3.180322892148979e-06, (8.5562175e-07, 0.0026502297, 0.0024686542, 0.09578625)\n",
      "   validation loss 1.4639600522059482e-05, (5.2593587e-06, 0.022048507, 0.0146399075, 0.09578625)\n",
      "decoder loss ratio: 0.000627, decoder SINDy loss  ratio: 0.000783\n",
      "Epoch 4900\n",
      "   training loss 2.3149457319959765e-06, (3.605868e-07, 0.0028581282, 0.0017005398, 0.096118264)\n",
      "   validation loss 1.1513882782310247e-05, (4.3514437e-06, 0.02269726, 0.010132786, 0.096118264)\n",
      "decoder loss ratio: 0.000519, decoder SINDy loss  ratio: 0.000542\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 1.053962591868185e-06, (2.824576e-07, 0.005212366, 0.0010217733, 0.09645689)\n",
      "   validation loss 1.0072108125314116e-05, (4.3631244e-06, 0.027037049, 0.008714263, 0.09645689)\n",
      "decoder loss ratio: 0.000520, decoder SINDy loss  ratio: 0.000466\n",
      "Epoch 100\n",
      "   training loss 1.3545985666496563e-06, (3.9554237e-07, 0.0014889184, 0.0017692206, 0.09787504)\n",
      "   validation loss 1.036745379678905e-05, (4.2075194e-06, 0.019592442, 0.010360624, 0.09787504)\n",
      "decoder loss ratio: 0.000502, decoder SINDy loss  ratio: 0.000554\n",
      "Epoch 200\n",
      "   training loss 2.6523002816247754e-06, (7.0902047e-07, 0.007502239, 0.0031363354, 0.09824888)\n",
      "   validation loss 1.2305778909649234e-05, (4.0768655e-06, 0.030726038, 0.013385222, 0.09824888)\n",
      "decoder loss ratio: 0.000486, decoder SINDy loss  ratio: 0.000716\n",
      "Epoch 300\n",
      "   training loss 7.669673323107418e-07, (2.1344769e-07, 0.0028445956, 0.0008225797, 0.09856423)\n",
      "   validation loss 8.800938303465955e-06, (3.7100897e-06, 0.023041483, 0.007877549, 0.09856423)\n",
      "decoder loss ratio: 0.000442, decoder SINDy loss  ratio: 0.000421\n",
      "Epoch 400\n",
      "   training loss 2.0665061128966045e-06, (9.840244e-07, 0.0041819573, 0.0017467677, 0.09874772)\n",
      "   validation loss 1.369319943478331e-05, (4.8616384e-06, 0.025957407, 0.01506738, 0.09874772)\n",
      "decoder loss ratio: 0.000580, decoder SINDy loss  ratio: 0.000805\n",
      "Epoch 500\n",
      "   training loss 7.524774446210358e-06, (1.4728915e-06, 0.011642746, 0.010939491, 0.09890034)\n",
      "   validation loss 1.9535415049176663e-05, (4.727357e-06, 0.038180437, 0.025798073, 0.09890034)\n",
      "decoder loss ratio: 0.000564, decoder SINDy loss  ratio: 0.001379\n",
      "Epoch 600\n",
      "   training loss 2.958062168545439e-07, (6.8196634e-08, 0.001245224, 0.00033069678, 0.09906718)\n",
      "   validation loss 7.368629667325877e-06, (3.2391558e-06, 0.021284007, 0.0061305473, 0.09906718)\n",
      "decoder loss ratio: 0.000386, decoder SINDy loss  ratio: 0.000328\n",
      "Epoch 700\n",
      "   training loss 7.964434189489111e-06, (2.2077802e-06, 0.002268895, 0.011286418, 0.09934733)\n",
      "   validation loss 1.9920626073144376e-05, (4.8354227e-06, 0.022919778, 0.027878426, 0.09934733)\n",
      "decoder loss ratio: 0.000576, decoder SINDy loss  ratio: 0.001490\n",
      "Epoch 800\n",
      "   training loss 4.618289040081436e-06, (1.6133953e-06, 0.013727747, 0.0046370127, 0.09941795)\n",
      "   validation loss 1.6824507838464342e-05, (4.547551e-06, 0.04289824, 0.02026409, 0.09941795)\n",
      "decoder loss ratio: 0.000542, decoder SINDy loss  ratio: 0.001083\n",
      "Epoch 900\n",
      "   training loss 5.825842208651011e-07, (2.5342862e-07, 0.0023761687, 0.00042069427, 0.09951594)\n",
      "   validation loss 8.620601875009015e-06, (3.3282474e-06, 0.022702735, 0.0083144335, 0.09951594)\n",
      "decoder loss ratio: 0.000397, decoder SINDy loss  ratio: 0.000444\n",
      "Epoch 1000\n",
      "   training loss 6.382659876180696e-07, (2.7949415e-07, 0.0021404887, 0.0005034947, 0.0992558)\n",
      "   validation loss 7.586151696159504e-06, (2.9180972e-06, 0.021805456, 0.007155563, 0.0992558)\n",
      "decoder loss ratio: 0.000348, decoder SINDy loss  ratio: 0.000383\n",
      "EXPERIMENT 1\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.013019464910030365, (0.007894683, 0.33849025, 10.195771, 0.9970446)\n",
      "   validation loss 0.017590142786502838, (0.008210007, 0.34362063, 18.705967, 0.9970446)\n",
      "decoder loss ratio: 0.978806, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.01232886966317892, (0.007224111, 2.1939944e-05, 10.195771, 0.687228)\n",
      "   validation loss 0.016881218180060387, (0.007521359, 4.3473225e-05, 18.705967, 0.687228)\n",
      "decoder loss ratio: 0.896704, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.01232677511870861, (0.0072262934, 3.0887564e-05, 10.195771, 0.2595059)\n",
      "   validation loss 0.016862958669662476, (0.0075073726, 0.00016033262, 18.705967, 0.2595059)\n",
      "decoder loss ratio: 0.895037, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.012325987219810486, (0.007227281, 0.00036249147, 10.195771, 0.080221936)\n",
      "   validation loss 0.016858572140336037, (0.0075047216, 0.0012738367, 18.705967, 0.080221936)\n",
      "decoder loss ratio: 0.894721, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.01232480350881815, (0.007226782, 0.0026892393, 10.195771, 5.6304518e-05)\n",
      "   validation loss 0.016856366768479347, (0.0075029875, 0.007899671, 18.705967, 5.6304518e-05)\n",
      "decoder loss ratio: 0.894514, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.011593230068683624, (0.0064204815, 1.4920894, 10.194698, 0.07944667)\n",
      "   validation loss 0.016237573698163033, (0.0068039335, 1.6231853, 18.703371, 0.07944667)\n",
      "decoder loss ratio: 0.811172, decoder SINDy loss  ratio: 0.999861\n",
      "THRESHOLDING: 4 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.009851514361798763, (0.005092334, 0.47495624, 9.468478, 0.119313814)\n",
      "   validation loss 0.014527526684105396, (0.005673992, 1.2547686, 17.579206, 0.119313814)\n",
      "decoder loss ratio: 0.676459, decoder SINDy loss  ratio: 0.939765\n",
      "Epoch 700\n",
      "   training loss 0.006365650333464146, (0.0040201964, 0.6753223, 4.6213355, 0.1019922)\n",
      "   validation loss 0.009892446920275688, (0.0045295516, 1.7237703, 10.5513735, 0.1019922)\n",
      "decoder loss ratio: 0.540018, decoder SINDy loss  ratio: 0.564065\n",
      "Epoch 800\n",
      "   training loss 0.0039785574190318584, (0.0028663455, 0.41562518, 2.181201, 0.083037086)\n",
      "   validation loss 0.006616628263145685, (0.0033382296, 1.3172356, 6.4234123, 0.083037086)\n",
      "decoder loss ratio: 0.397987, decoder SINDy loss  ratio: 0.343388\n",
      "Epoch 900\n",
      "   training loss 0.002432122826576233, (0.0019443971, 0.29107007, 0.9449049, 0.07197489)\n",
      "   validation loss 0.004615278914570808, (0.002620381, 1.0302203, 3.885334, 0.07197489)\n",
      "decoder loss ratio: 0.312405, decoder SINDy loss  ratio: 0.207706\n",
      "Epoch 1000\n",
      "   training loss 0.0016880743205547333, (0.0014444084, 0.2167941, 0.46413186, 0.07603315)\n",
      "   validation loss 0.0034802546724677086, (0.0020973063, 0.8480291, 2.679573, 0.07603315)\n",
      "decoder loss ratio: 0.250043, decoder SINDy loss  ratio: 0.143247\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.0008242179173976183, (0.00072037283, 0.2291321, 0.18356346, 0.060674086)\n",
      "   validation loss 0.002595428843051195, (0.0016470525, 0.74598235, 1.8209407, 0.060674086)\n",
      "decoder loss ratio: 0.196363, decoder SINDy loss  ratio: 0.097345\n",
      "Epoch 1200\n",
      "   training loss 0.00037062831688672304, (0.00032744938, 0.110564664, 0.07414264, 0.057935912)\n",
      "   validation loss 0.0021317801438272, (0.0014490463, 0.43374512, 1.3209344, 0.057935912)\n",
      "decoder loss ratio: 0.172757, decoder SINDy loss  ratio: 0.070616\n",
      "Epoch 1300\n",
      "   training loss 0.00019813452672678977, (0.00017238375, 0.06418218, 0.043917663, 0.05828482)\n",
      "   validation loss 0.001851324806921184, (0.0013043361, 0.31874666, 1.0609367, 0.05828482)\n",
      "decoder loss ratio: 0.155504, decoder SINDy loss  ratio: 0.056716\n",
      "Epoch 1400\n",
      "   training loss 0.00011646653001662344, (9.211983e-05, 0.046671737, 0.042844612, 0.05908069)\n",
      "   validation loss 0.0016553361201658845, (0.0011831316, 0.2500534, 0.9182221, 0.05908069)\n",
      "decoder loss ratio: 0.141054, decoder SINDy loss  ratio: 0.049087\n",
      "Epoch 1500\n",
      "   training loss 8.009296288946643e-05, (5.254789e-05, 0.036191683, 0.05025863, 0.060617123)\n",
      "   validation loss 0.00150921824388206, (0.0010927602, 0.20285961, 0.8114175, 0.060617123)\n",
      "decoder loss ratio: 0.130280, decoder SINDy loss  ratio: 0.043377\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 4.7804445785004646e-05, (3.5162473e-05, 0.03551779, 0.020611778, 0.056019556)\n",
      "   validation loss 0.0013740930007770658, (0.0010213437, 0.175827, 0.6867954, 0.056019556)\n",
      "decoder loss ratio: 0.121766, decoder SINDy loss  ratio: 0.036715\n",
      "Epoch 1700\n",
      "   training loss 4.1070234146900475e-05, (2.8487042e-05, 0.03088208, 0.020979954, 0.054911066)\n",
      "   validation loss 0.0012762992409989238, (0.0009603953, 0.14556876, 0.6161527, 0.054911066)\n",
      "decoder loss ratio: 0.114499, decoder SINDy loss  ratio: 0.032939\n",
      "Epoch 1800\n",
      "   training loss 2.7737660275306553e-05, (2.024389e-05, 0.02785292, 0.0110780075, 0.05621207)\n",
      "   validation loss 0.00116289674770087, (0.000897771, 0.12936275, 0.51619095, 0.05621207)\n",
      "decoder loss ratio: 0.107033, decoder SINDy loss  ratio: 0.027595\n",
      "Epoch 1900\n",
      "   training loss 2.1390829715528525e-05, (1.3989786e-05, 0.0266779, 0.010993106, 0.057059497)\n",
      "   validation loss 0.0010448317043483257, (0.00082044466, 0.1506877, 0.43256414, 0.057059497)\n",
      "decoder loss ratio: 0.097814, decoder SINDy loss  ratio: 0.023124\n",
      "Epoch 2000\n",
      "   training loss 1.3698821021534968e-05, (6.783159e-06, 0.020816479, 0.010596343, 0.057666603)\n",
      "   validation loss 0.0008980571292340755, (0.0007043421, 0.17462663, 0.36881408, 0.057666603)\n",
      "decoder loss ratio: 0.083972, decoder SINDy loss  ratio: 0.019716\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 1.1431878192524891e-05, (4.893016e-06, 0.01763437, 0.010146427, 0.05839305)\n",
      "   validation loss 0.0007745805778540671, (0.00059393217, 0.18102835, 0.34202614, 0.05839305)\n",
      "decoder loss ratio: 0.070809, decoder SINDy loss  ratio: 0.018284\n",
      "Epoch 2200\n",
      "   training loss 1.2102217624487821e-05, (5.8219744e-06, 0.015708063, 0.00980669, 0.059149463)\n",
      "   validation loss 0.0006812000647187233, (0.00051149837, 0.17888577, 0.32033172, 0.059149463)\n",
      "decoder loss ratio: 0.060981, decoder SINDy loss  ratio: 0.017125\n",
      "Epoch 2300\n",
      "   training loss 1.2072025128873065e-05, (6.002421e-06, 0.014453102, 0.009497046, 0.05984262)\n",
      "   validation loss 0.0005968391778878868, (0.00044554056, 0.18259482, 0.28314084, 0.05984262)\n",
      "decoder loss ratio: 0.053118, decoder SINDy loss  ratio: 0.015136\n",
      "Epoch 2400\n",
      "   training loss 1.085486110241618e-05, (5.020222e-06, 0.013378188, 0.009120087, 0.060568642)\n",
      "   validation loss 0.0005232151597738266, (0.00039445795, 0.17767428, 0.23853563, 0.060568642)\n",
      "decoder loss ratio: 0.047028, decoder SINDy loss  ratio: 0.012752\n",
      "Epoch 2500\n",
      "   training loss 9.520226740278304e-06, (4.0054742e-06, 0.012108119, 0.008587502, 0.061559547)\n",
      "   validation loss 0.0004666673776227981, (0.00035802793, 0.16236196, 0.19981146, 0.061559547)\n",
      "decoder loss ratio: 0.042684, decoder SINDy loss  ratio: 0.010682\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 8.522405551047996e-06, (3.3905985e-06, 0.010748766, 0.0079324255, 0.06281564)\n",
      "   validation loss 0.00042285319068469107, (0.0003295901, 0.16443628, 0.16882624, 0.06281564)\n",
      "decoder loss ratio: 0.039294, decoder SINDy loss  ratio: 0.009025\n",
      "Epoch 2700\n",
      "   training loss 7.679911504965276e-06, (2.9237342e-06, 0.0094379, 0.007284418, 0.064207345)\n",
      "   validation loss 0.0003880660515278578, (0.0003069884, 0.18263553, 0.14260767, 0.064207345)\n",
      "decoder loss ratio: 0.036599, decoder SINDy loss  ratio: 0.007624\n",
      "Epoch 2800\n",
      "   training loss 7.0338387558877e-06, (2.6067464e-06, 0.008323735, 0.0067104995, 0.06556559)\n",
      "   validation loss 0.0003549003158695996, (0.00028531856, 0.16418307, 0.12143391, 0.06556559)\n",
      "decoder loss ratio: 0.034016, decoder SINDy loss  ratio: 0.006492\n",
      "Epoch 2900\n",
      "   training loss 6.494079116237117e-06, (2.3588568e-06, 0.0072992775, 0.006202417, 0.06690497)\n",
      "   validation loss 0.000324793451000005, (0.00026418883, 0.14591524, 0.10527967, 0.06690497)\n",
      "decoder loss ratio: 0.031497, decoder SINDy loss  ratio: 0.005628\n",
      "Epoch 3000\n",
      "   training loss 6.072500582376961e-06, (2.1886678e-06, 0.0063493997, 0.0057677147, 0.06825052)\n",
      "   validation loss 0.00029902675305493176, (0.00024547474, 0.12933065, 0.09280592, 0.06825052)\n",
      "decoder loss ratio: 0.029266, decoder SINDy loss  ratio: 0.004961\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 5.7147503866872285e-06, (2.0461014e-06, 0.005490828, 0.005396011, 0.06961021)\n",
      "   validation loss 0.0002768191625364125, (0.00022896251, 0.11602856, 0.0827182, 0.06961021)\n",
      "decoder loss ratio: 0.027297, decoder SINDy loss  ratio: 0.004422\n",
      "Epoch 3200\n",
      "   training loss 5.416030944616068e-06, (1.9344507e-06, 0.0047172164, 0.0050721583, 0.07096403)\n",
      "   validation loss 0.0002570799260865897, (0.00021396809, 0.10473252, 0.07433118, 0.07096403)\n",
      "decoder loss ratio: 0.025510, decoder SINDy loss  ratio: 0.003974\n",
      "Epoch 3300\n",
      "   training loss 5.1510819503164385e-06, (1.8290805e-06, 0.00401593, 0.0047960375, 0.072318606)\n",
      "   validation loss 0.00023921149841044098, (0.00020019505, 0.093590066, 0.067227535, 0.072318606)\n",
      "decoder loss ratio: 0.023867, decoder SINDy loss  ratio: 0.003594\n",
      "Epoch 3400\n",
      "   training loss 4.913129487249535e-06, (1.7351098e-06, 0.0033907332, 0.0045439624, 0.073650144)\n",
      "   validation loss 0.00022289689513854682, (0.00018751237, 0.08232878, 0.061063133, 0.073650144)\n",
      "decoder loss ratio: 0.022355, decoder SINDy loss  ratio: 0.003264\n",
      "Epoch 3500\n",
      "   training loss 4.722332050732803e-06, (1.6557871e-06, 0.0028521926, 0.0043497966, 0.07490372)\n",
      "   validation loss 0.0002079661499010399, (0.00017571311, 0.07196597, 0.05581142, 0.07490372)\n",
      "decoder loss ratio: 0.020949, decoder SINDy loss  ratio: 0.002984\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 4.525883923633955e-06, (1.5553194e-06, 0.0024966246, 0.004179011, 0.075622745)\n",
      "   validation loss 0.00019401396275497973, (0.00016449198, 0.06254056, 0.05127742, 0.075622745)\n",
      "decoder loss ratio: 0.019611, decoder SINDy loss  ratio: 0.002741\n",
      "Epoch 3700\n",
      "   training loss 4.356581030151574e-06, (1.4689399e-06, 0.0022910843, 0.0040244674, 0.076085314)\n",
      "   validation loss 0.00018096278654411435, (0.00015383666, 0.054579187, 0.047272626, 0.076085314)\n",
      "decoder loss ratio: 0.018341, decoder SINDy loss  ratio: 0.002527\n",
      "Epoch 3800\n",
      "   training loss 4.1607308958191425e-06, (1.3857602e-06, 0.0020834156, 0.0038104407, 0.07655795)\n",
      "   validation loss 0.00016860442701727152, (0.00014366778, 0.047853217, 0.043556828, 0.07655795)\n",
      "decoder loss ratio: 0.017128, decoder SINDy loss  ratio: 0.002328\n",
      "Epoch 3900\n",
      "   training loss 4.001617071480723e-06, (1.3114714e-06, 0.0018924513, 0.0036504709, 0.07702876)\n",
      "   validation loss 0.00015682258526794612, (0.0001337654, 0.042080097, 0.040365774, 0.07702876)\n",
      "decoder loss ratio: 0.015948, decoder SINDy loss  ratio: 0.002158\n",
      "Epoch 4000\n",
      "   training loss 4.056410944031086e-06, (1.2888621e-06, 0.0017039812, 0.003814798, 0.077495046)\n",
      "   validation loss 0.00014578628179151565, (0.00012406457, 0.03676065, 0.03821746, 0.077495046)\n",
      "decoder loss ratio: 0.014791, decoder SINDy loss  ratio: 0.002043\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 4.229969363223063e-06, (1.2842193e-06, 0.0014855027, 0.0041840146, 0.07794676)\n",
      "   validation loss 0.0001353257248410955, (0.000114554576, 0.03223487, 0.036759872, 0.07794676)\n",
      "decoder loss ratio: 0.013657, decoder SINDy loss  ratio: 0.001965\n",
      "Epoch 4200\n",
      "   training loss 3.481734438537387e-06, (1.0589204e-06, 0.0012810479, 0.0031499017, 0.07838106)\n",
      "   validation loss 0.00012355145008768886, (0.0001050421, 0.030046955, 0.032446377, 0.07838106)\n",
      "decoder loss ratio: 0.012523, decoder SINDy loss  ratio: 0.001735\n",
      "Epoch 4300\n",
      "   training loss 3.2988448310788954e-06, (1.0463494e-06, 0.0014716851, 0.0027816729, 0.078807466)\n",
      "   validation loss 0.00011324688966851681, (9.591207e-05, 0.030171612, 0.03007632, 0.078807466)\n",
      "decoder loss ratio: 0.011435, decoder SINDy loss  ratio: 0.001608\n",
      "Epoch 4400\n",
      "   training loss 3.328174443595344e-06, (1.0221898e-06, 0.0010739036, 0.0029201887, 0.079219505)\n",
      "   validation loss 0.00010383020708104596, (8.712088e-05, 0.029660754, 0.028868195, 0.079219505)\n",
      "decoder loss ratio: 0.010387, decoder SINDy loss  ratio: 0.001543\n",
      "Epoch 4500\n",
      "   training loss 3.219491190975532e-06, (9.552613e-07, 0.0009603847, 0.0028399997, 0.07962107)\n",
      "   validation loss 9.429275814909488e-05, (7.847177e-05, 0.029222813, 0.027127273, 0.07962107)\n",
      "decoder loss ratio: 0.009355, decoder SINDy loss  ratio: 0.001450\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 3.139328782708617e-06, (9.044469e-07, 0.00085070444, 0.0027846915, 0.08000008)\n",
      "   validation loss 8.523005817551166e-05, (7.019836e-05, 0.028557384, 0.025607655, 0.08000008)\n",
      "decoder loss ratio: 0.008369, decoder SINDy loss  ratio: 0.001369\n",
      "Epoch 4700\n",
      "   training loss 3.043343667741283e-06, (8.3968126e-07, 0.0007511985, 0.0027250818, 0.08035616)\n",
      "   validation loss 7.667252066312358e-05, (6.235786e-05, 0.028006073, 0.024221586, 0.08035616)\n",
      "decoder loss ratio: 0.007434, decoder SINDy loss  ratio: 0.001295\n",
      "Epoch 4800\n",
      "   training loss 2.966803094750503e-06, (7.94634e-07, 0.0006637891, 0.0026642533, 0.08068527)\n",
      "   validation loss 6.865090108476579e-05, (5.4999076e-05, 0.027477575, 0.022942184, 0.08068527)\n",
      "decoder loss ratio: 0.006557, decoder SINDy loss  ratio: 0.001226\n",
      "Epoch 4900\n",
      "   training loss 2.8918793759658e-06, (7.4914755e-07, 0.000586529, 0.0026068457, 0.08099826)\n",
      "   validation loss 6.125428626546636e-05, (4.8227488e-05, 0.026605424, 0.021773085, 0.08099826)\n",
      "decoder loss ratio: 0.005750, decoder SINDy loss  ratio: 0.001164\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 2.6613438421918545e-06, (1.1116587e-06, 0.00048046085, 0.003051324, 0.08128422)\n",
      "   validation loss 5.41090703336522e-05, (4.246857e-05, 0.025285555, 0.02075244, 0.08128422)\n",
      "decoder loss ratio: 0.005063, decoder SINDy loss  ratio: 0.001109\n",
      "Epoch 100\n",
      "   training loss 2.867992861865787e-06, (9.0142606e-07, 0.0009965114, 0.003833482, 0.0821804)\n",
      "   validation loss 4.997050200472586e-05, (3.7115617e-05, 0.025546737, 0.023155095, 0.0821804)\n",
      "decoder loss ratio: 0.004425, decoder SINDy loss  ratio: 0.001238\n",
      "Epoch 200\n",
      "   training loss 1.308279252043576e-06, (4.1167706e-07, 0.000967673, 0.001696437, 0.08247476)\n",
      "   validation loss 4.0780862036626786e-05, (3.1411775e-05, 0.024413671, 0.01629681, 0.08247476)\n",
      "decoder loss ratio: 0.003745, decoder SINDy loss  ratio: 0.000871\n",
      "Epoch 300\n",
      "   training loss 1.0029219765783637e-06, (3.4821184e-07, 0.00046187706, 0.0012632324, 0.08277261)\n",
      "   validation loss 3.588833351386711e-05, (2.7284621e-05, 0.022660838, 0.014941346, 0.08277261)\n",
      "decoder loss ratio: 0.003253, decoder SINDy loss  ratio: 0.000799\n",
      "Epoch 400\n",
      "   training loss 1.9579870240704622e-06, (6.018489e-07, 0.0017130118, 0.0025409749, 0.08304942)\n",
      "   validation loss 3.45771259162575e-05, (2.444393e-05, 0.023827245, 0.017883662, 0.08304942)\n",
      "decoder loss ratio: 0.002914, decoder SINDy loss  ratio: 0.000956\n",
      "Epoch 500\n",
      "   training loss 3.0818893037576345e-07, (1.9139337e-07, 0.00017522665, 0.00021606844, 0.083350234)\n",
      "   validation loss 2.7165304345544428e-05, (2.0493948e-05, 0.01963186, 0.011379526, 0.083350234)\n",
      "decoder loss ratio: 0.002443, decoder SINDy loss  ratio: 0.000608\n",
      "Epoch 600\n",
      "   training loss 3.20964591082884e-06, (9.352211e-07, 0.0011123366, 0.004437616, 0.083535664)\n",
      "   validation loss 3.093894338235259e-05, (1.9206376e-05, 0.020504111, 0.021414725, 0.083535664)\n",
      "decoder loss ratio: 0.002290, decoder SINDy loss  ratio: 0.001145\n",
      "Epoch 700\n",
      "   training loss 7.902221454969549e-07, (3.0587472e-07, 0.0002810424, 0.0009405906, 0.08375659)\n",
      "   validation loss 2.294680234626867e-05, (1.6012555e-05, 0.017940197, 0.012074476, 0.08375659)\n",
      "decoder loss ratio: 0.001909, decoder SINDy loss  ratio: 0.000645\n",
      "Epoch 800\n",
      "   training loss 3.6418589388631517e-07, (1.9196352e-07, 0.0001647297, 0.00032797173, 0.0839866)\n",
      "   validation loss 1.9532739315764047e-05, (1.3838141e-05, 0.016604783, 0.009728718, 0.0839866)\n",
      "decoder loss ratio: 0.001650, decoder SINDy loss  ratio: 0.000520\n",
      "Epoch 900\n",
      "   training loss 3.5754565033130348e-06, (9.276252e-07, 0.0006000189, 0.0052356604, 0.084192015)\n",
      "   validation loss 2.2801941668149084e-05, (1.3271268e-05, 0.016681494, 0.0173932, 0.084192015)\n",
      "decoder loss ratio: 0.001582, decoder SINDy loss  ratio: 0.000930\n",
      "Epoch 1000\n",
      "   training loss 1.0661419764801394e-06, (4.6188975e-07, 0.00059191213, 0.0011493133, 0.0844616)\n",
      "   validation loss 1.9319197235745378e-05, (1.1860055e-05, 0.016284283, 0.013289855, 0.0844616)\n",
      "decoder loss ratio: 0.001414, decoder SINDy loss  ratio: 0.000710\n",
      "EXPERIMENT 2\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.013018484227359295, (0.007844925, 1.3142875, 10.195771, 0.99586374)\n",
      "   validation loss 0.01758068986237049, (0.0081516085, 1.3227175, 18.705969, 0.99586374)\n",
      "decoder loss ratio: 0.971844, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.012327938340604305, (0.007223622, 7.2686373e-07, 10.195771, 0.64305955)\n",
      "   validation loss 0.016882695257663727, (0.0075232806, 9.262298e-06, 18.705967, 0.64305955)\n",
      "decoder loss ratio: 0.896934, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.012325762771070004, (0.0072260997, 1.9769983e-05, 10.195771, 0.17764322)\n",
      "   validation loss 0.01686241291463375, (0.00750765, 4.4007524e-05, 18.705967, 0.17764322)\n",
      "decoder loss ratio: 0.895070, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.012325379997491837, (0.007227309, 0.000114496725, 10.195771, 0.0178822)\n",
      "   validation loss 0.016858115792274475, (0.007504938, 0.00031923555, 18.705967, 0.0178822)\n",
      "decoder loss ratio: 0.894747, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.012325496412813663, (0.007227594, 0.00034306265, 10.19577, 3.3061722e-05)\n",
      "   validation loss 0.016857126727700233, (0.007504094, 0.00097027014, 18.705967, 3.3061722e-05)\n",
      "decoder loss ratio: 0.894646, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.012325468473136425, (0.007227531, 0.0009945001, 10.195771, 4.729915e-05)\n",
      "   validation loss 0.01685660518705845, (0.0075034746, 0.0029360205, 18.705967, 4.729915e-05)\n",
      "decoder loss ratio: 0.894572, decoder SINDy loss  ratio: 1.000000\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.012324748560786247, (0.0072266585, 0.0040669823, 10.195771, 8.6283835e-06)\n",
      "   validation loss 0.01685541495680809, (0.007501836, 0.011925033, 18.705967, 8.6283835e-06)\n",
      "decoder loss ratio: 0.894377, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 700\n",
      "   training loss 0.01226479560136795, (0.0071370415, 0.59743667, 10.1957655, 8.3105915e-06)\n",
      "   validation loss 0.01668398827314377, (0.0072751115, 1.1188403, 18.705866, 8.3105915e-06)\n",
      "decoder loss ratio: 0.867347, decoder SINDy loss  ratio: 0.999995\n",
      "Epoch 800\n",
      "   training loss 0.011656958609819412, (0.006526375, 0.6593075, 10.195235, 6.846352e-06)\n",
      "   validation loss 0.016010155901312828, (0.0066032093, 1.0936826, 18.704525, 6.846352e-06)\n",
      "decoder loss ratio: 0.787242, decoder SINDy loss  ratio: 0.999923\n",
      "Epoch 900\n",
      "   training loss 0.011438731104135513, (0.0063230707, 0.361258, 10.195195, 9.497216e-06)\n",
      "   validation loss 0.015950851142406464, (0.0065684402, 0.60267586, 18.704552, 9.497216e-06)\n",
      "decoder loss ratio: 0.783097, decoder SINDy loss  ratio: 0.999924\n",
      "Epoch 1000\n",
      "   training loss 0.011327695101499557, (0.006217609, 0.25023094, 10.195148, 1.1465279e-05)\n",
      "   validation loss 0.015924137085676193, (0.0065506566, 0.42512858, 18.704445, 1.1465279e-05)\n",
      "decoder loss ratio: 0.780976, decoder SINDy loss  ratio: 0.999919\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.01126350648701191, (0.0061557456, 0.20508209, 10.195013, 5.9241115e-06)\n",
      "   validation loss 0.0159120075404644, (0.006542617, 0.34595394, 18.704182, 5.9241115e-06)\n",
      "decoder loss ratio: 0.780018, decoder SINDy loss  ratio: 0.999905\n",
      "Epoch 1200\n",
      "   training loss 0.011219611391425133, (0.0061138384, 0.16684276, 10.1948595, 9.572211e-06)\n",
      "   validation loss 0.01590118557214737, (0.0065354058, 0.27718422, 18.703842, 9.572211e-06)\n",
      "decoder loss ratio: 0.779158, decoder SINDy loss  ratio: 0.999886\n",
      "Epoch 1300\n",
      "   training loss 0.011186358518898487, (0.006081948, 0.14491403, 10.194329, 9.763481e-06)\n",
      "   validation loss 0.0158929955214262, (0.0065296288, 0.23832358, 18.702902, 9.763481e-06)\n",
      "decoder loss ratio: 0.778469, decoder SINDy loss  ratio: 0.999836\n",
      "Epoch 1400\n",
      "   training loss 0.011157196946442127, (0.0060536405, 0.1406842, 10.193044, 9.474549e-06)\n",
      "   validation loss 0.015882954001426697, (0.00652115, 0.22921199, 18.700686, 9.474549e-06)\n",
      "decoder loss ratio: 0.777459, decoder SINDy loss  ratio: 0.999718\n",
      "Epoch 1500\n",
      "   training loss 0.011114329099655151, (0.006011666, 0.18406278, 10.186919, 8.576845e-06)\n",
      "   validation loss 0.015855539590120316, (0.0064950925, 0.30442572, 18.690449, 8.576845e-06)\n",
      "decoder loss ratio: 0.774352, decoder SINDy loss  ratio: 0.999170\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 0.010357914492487907, (0.0053490195, 1.6791484, 9.8498745, 7.919794e-06)\n",
      "   validation loss 0.015050521120429039, (0.0058310744, 2.696778, 18.169216, 7.919794e-06)\n",
      "decoder loss ratio: 0.695187, decoder SINDy loss  ratio: 0.971306\n",
      "Epoch 1700\n",
      "   training loss 0.008074303157627583, (0.004539514, 3.826148, 6.686962, 8.681192e-06)\n",
      "   validation loss 0.012085983529686928, (0.0051426375, 5.717386, 13.314953, 8.681192e-06)\n",
      "decoder loss ratio: 0.613111, decoder SINDy loss  ratio: 0.711802\n",
      "Epoch 1800\n",
      "   training loss 0.007239350117743015, (0.0042526815, 2.7685142, 5.696486, 1.0632856e-05)\n",
      "   validation loss 0.010827427729964256, (0.004821406, 4.0142865, 11.610615, 1.0632856e-05)\n",
      "decoder loss ratio: 0.574813, decoder SINDy loss  ratio: 0.620690\n",
      "Epoch 1900\n",
      "   training loss 0.0066070640459656715, (0.004070818, 3.0811749, 4.7643743, 1.1096382e-05)\n",
      "   validation loss 0.009901629760861397, (0.0046014395, 4.3449936, 10.165881, 1.1096382e-05)\n",
      "decoder loss ratio: 0.548589, decoder SINDy loss  ratio: 0.543457\n",
      "Epoch 2000\n",
      "   training loss 0.006240974646061659, (0.0039128116, 2.410688, 4.4152565, 6.8345557e-06)\n",
      "   validation loss 0.009516973048448563, (0.0045165406, 3.4738603, 9.653478, 6.8345557e-06)\n",
      "decoder loss ratio: 0.538467, decoder SINDy loss  ratio: 0.516064\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 0.005938736721873283, (0.0037454597, 2.0888796, 4.1776657, 8.499304e-06)\n",
      "   validation loss 0.009225492365658283, (0.0044444613, 2.9816797, 9.263894, 8.499304e-06)\n",
      "decoder loss ratio: 0.529873, decoder SINDy loss  ratio: 0.495237\n",
      "Epoch 2200\n",
      "   training loss 0.0056137265637516975, (0.0035501989, 1.8283703, 3.9442184, 9.7266375e-06)\n",
      "   validation loss 0.009002232924103737, (0.004376539, 2.7917604, 8.972212, 9.7266375e-06)\n",
      "decoder loss ratio: 0.521776, decoder SINDy loss  ratio: 0.479644\n",
      "Epoch 2300\n",
      "   training loss 0.005239035468548536, (0.0033239585, 1.6475947, 3.6653948, 9.167976e-06)\n",
      "   validation loss 0.00874486193060875, (0.0043396666, 2.4291284, 8.567478, 9.167976e-06)\n",
      "decoder loss ratio: 0.517380, decoder SINDy loss  ratio: 0.458008\n",
      "Epoch 2400\n",
      "   training loss 0.004769580438733101, (0.0030267932, 1.5634516, 3.329229, 1.1418081e-05)\n",
      "   validation loss 0.008486343547701836, (0.0043060896, 2.3064165, 8.129867, 1.1418081e-05)\n",
      "decoder loss ratio: 0.513377, decoder SINDy loss  ratio: 0.434614\n",
      "Epoch 2500\n",
      "   training loss 0.004051798023283482, (0.0025370016, 1.5223534, 2.8773572, 8.391393e-06)\n",
      "   validation loss 0.007956010289490223, (0.004139271, 2.263046, 7.407173, 8.391393e-06)\n",
      "decoder loss ratio: 0.493488, decoder SINDy loss  ratio: 0.395979\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 0.00328697357326746, (0.002185472, 0.9545284, 2.1075501, 9.441297e-06)\n",
      "   validation loss 0.007103532087057829, (0.0038445382, 2.0303636, 6.3149505, 9.441297e-06)\n",
      "decoder loss ratio: 0.458350, decoder SINDy loss  ratio: 0.337590\n",
      "Epoch 2700\n",
      "   training loss 0.0017549690091982484, (0.0012401015, 0.21876115, 1.0078588, 1.0054517e-05)\n",
      "   validation loss 0.005223159212619066, (0.0029832516, 0.6412689, 4.4156885, 1.0054517e-05)\n",
      "decoder loss ratio: 0.355666, decoder SINDy loss  ratio: 0.236058\n",
      "Epoch 2800\n",
      "   training loss 0.0009128748206421733, (0.00069576903, 0.15710022, 0.41850126, 9.192197e-06)\n",
      "   validation loss 0.003802486229687929, (0.0022922808, 0.79127127, 2.9412835, 9.192197e-06)\n",
      "decoder loss ratio: 0.273288, decoder SINDy loss  ratio: 0.157238\n",
      "Epoch 2900\n",
      "   training loss 0.0006678648642264307, (0.000561732, 0.15261382, 0.19700432, 8.203294e-06)\n",
      "   validation loss 0.0030528840143233538, (0.001956484, 1.2578981, 2.06701, 8.203294e-06)\n",
      "decoder loss ratio: 0.233254, decoder SINDy loss  ratio: 0.110500\n",
      "Epoch 3000\n",
      "   training loss 0.000575076206587255, (0.00049760524, 0.12102694, 0.14283913, 7.496133e-06)\n",
      "   validation loss 0.002759518101811409, (0.0018349446, 1.0698904, 1.7421578, 7.496133e-06)\n",
      "decoder loss ratio: 0.218764, decoder SINDy loss  ratio: 0.093134\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 0.000491547689307481, (0.0004313501, 0.1037723, 0.11001773, 1.3792061e-05)\n",
      "   validation loss 0.0025563512463122606, (0.0017594786, 0.9203938, 1.5017055, 1.3792061e-05)\n",
      "decoder loss ratio: 0.209767, decoder SINDy loss  ratio: 0.080279\n",
      "Epoch 3200\n",
      "   training loss 0.00040381847065873444, (0.00035352437, 0.09191736, 0.09139629, 9.012479e-06)\n",
      "   validation loss 0.002400400582700968, (0.0016965983, 0.7760498, 1.3299998, 9.012479e-06)\n",
      "decoder loss ratio: 0.202270, decoder SINDy loss  ratio: 0.071100\n",
      "Epoch 3300\n",
      "   training loss 0.0003171463613398373, (0.00027274986, 0.08589146, 0.080203645, 1.0408329e-05)\n",
      "   validation loss 0.0022629026789218187, (0.0016306036, 0.671843, 1.197414, 1.0408329e-05)\n",
      "decoder loss ratio: 0.194402, decoder SINDy loss  ratio: 0.064012\n",
      "Epoch 3400\n",
      "   training loss 0.00022400563466362655, (0.00018423713, 0.08081976, 0.07145486, 8.376522e-06)\n",
      "   validation loss 0.002028341870754957, (0.001472017, 0.56534904, 1.0561148, 8.376522e-06)\n",
      "decoder loss ratio: 0.175495, decoder SINDy loss  ratio: 0.056459\n",
      "Epoch 3500\n",
      "   training loss 0.00012761390826199204, (8.955546e-05, 0.07234762, 0.06888197, 6.8837126e-06)\n",
      "   validation loss 0.0017033318290486932, (0.0012178309, 0.44986427, 0.926015, 6.8837126e-06)\n",
      "decoder loss ratio: 0.145191, decoder SINDy loss  ratio: 0.049504\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 6.914534606039524e-05, (3.3130003e-05, 0.06648318, 0.06538215, 1.0499632e-05)\n",
      "   validation loss 0.0014536717208102345, (0.0010471587, 0.3229624, 0.7807294, 1.0499632e-05)\n",
      "decoder loss ratio: 0.124843, decoder SINDy loss  ratio: 0.041737\n",
      "Epoch 3700\n",
      "   training loss 5.390975275076926e-05, (1.8459543e-05, 0.06357995, 0.06454224, 8.6814125e-06)\n",
      "   validation loss 0.001268724794499576, (0.00093197223, 0.26839274, 0.6466655, 8.6814125e-06)\n",
      "decoder loss ratio: 0.111111, decoder SINDy loss  ratio: 0.034570\n",
      "Epoch 3800\n",
      "   training loss 4.8562968004262075e-05, (1.3240835e-05, 0.060655065, 0.06457863, 6.226699e-06)\n",
      "   validation loss 0.0011313469149172306, (0.00085981976, 0.24721086, 0.5183329, 6.226699e-06)\n",
      "decoder loss ratio: 0.102509, decoder SINDy loss  ratio: 0.027709\n",
      "Epoch 3900\n",
      "   training loss 4.3412332161096856e-05, (8.852223e-06, 0.057823647, 0.06333766, 9.753282e-06)\n",
      "   validation loss 0.0009890039218589664, (0.00077509356, 0.23530884, 0.40428942, 9.753282e-06)\n",
      "decoder loss ratio: 0.092407, decoder SINDy loss  ratio: 0.021613\n",
      "Epoch 4000\n",
      "   training loss 4.450414780876599e-05, (8.9782825e-06, 0.05517538, 0.06553396, 1.1768699e-05)\n",
      "   validation loss 0.0008005014387890697, (0.00063089316, 0.21046475, 0.31816983, 1.1768699e-05)\n",
      "decoder loss ratio: 0.075216, decoder SINDy loss  ratio: 0.017009\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 4.590772005030885e-05, (1.0127647e-05, 0.053242303, 0.06623574, 8.438616e-06)\n",
      "   validation loss 0.0005895181675441563, (0.00046085368, 0.18663825, 0.23866497, 8.438616e-06)\n",
      "decoder loss ratio: 0.054943, decoder SINDy loss  ratio: 0.012759\n",
      "Epoch 4200\n",
      "   training loss 4.568828080664389e-05, (9.822833e-06, 0.05240807, 0.066489905, 9.252728e-06)\n",
      "   validation loss 0.00045667722588405013, (0.00035377333, 0.14724731, 0.1910829, 9.252728e-06)\n",
      "decoder loss ratio: 0.042177, decoder SINDy loss  ratio: 0.010215\n",
      "Epoch 4300\n",
      "   training loss 4.4523632823256776e-05, (8.8150855e-06, 0.052203238, 0.06619661, 7.5536723e-06)\n",
      "   validation loss 0.0003876631089951843, (0.00029801254, 0.11643607, 0.16765729, 7.5536723e-06)\n",
      "decoder loss ratio: 0.035529, decoder SINDy loss  ratio: 0.008963\n",
      "Epoch 4400\n",
      "   training loss 4.2620602471288294e-05, (7.543907e-06, 0.051864374, 0.06496676, 9.368966e-06)\n",
      "   validation loss 0.0003310581960249692, (0.0002527661, 0.10222685, 0.14636134, 9.368966e-06)\n",
      "decoder loss ratio: 0.030135, decoder SINDy loss  ratio: 0.007824\n",
      "Epoch 4500\n",
      "   training loss 4.01730285375379e-05, (6.2809745e-06, 0.051409476, 0.06264297, 9.428089e-06)\n",
      "   validation loss 0.0002802264934871346, (0.00021209737, 0.09235278, 0.12702276, 9.428089e-06)\n",
      "decoder loss ratio: 0.025286, decoder SINDy loss  ratio: 0.006790\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 3.9748018025420606e-05, (5.4610696e-06, 0.05091046, 0.06348261, 1.1492579e-05)\n",
      "   validation loss 0.00023476345813833177, (0.00017255994, 0.083950154, 0.116011746, 1.1492579e-05)\n",
      "decoder loss ratio: 0.020573, decoder SINDy loss  ratio: 0.006202\n",
      "Epoch 4700\n",
      "   training loss 3.899224611814134e-05, (4.735901e-06, 0.05043291, 0.063469246, 7.4908967e-06)\n",
      "   validation loss 0.00019197395886294544, (0.00013488831, 0.075609654, 0.10661017, 7.4908967e-06)\n",
      "decoder loss ratio: 0.016082, decoder SINDy loss  ratio: 0.005699\n",
      "Epoch 4800\n",
      "   training loss 4.197081216261722e-05, (5.1169955e-06, 0.050105315, 0.06869689, 1.0416094e-05)\n",
      "   validation loss 0.0001609406463103369, (0.00010293699, 0.068814546, 0.10912567, 1.0416094e-05)\n",
      "decoder loss ratio: 0.012272, decoder SINDy loss  ratio: 0.005834\n",
      "Epoch 4900\n",
      "   training loss 3.8549631426576525e-05, (3.6667952e-06, 0.04969633, 0.064795844, 9.875763e-06)\n",
      "   validation loss 0.00012548705853987485, (7.373398e-05, 0.06355628, 0.09715031, 9.875763e-06)\n",
      "decoder loss ratio: 0.008791, decoder SINDy loss  ratio: 0.005194\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 4.1140247049042955e-05, (1.484572e-06, 0.04922055, 0.074389294, 7.696224e-06)\n",
      "   validation loss 0.00010145377018488944, (5.327046e-05, 0.059704553, 0.090396166, 7.696224e-06)\n",
      "decoder loss ratio: 0.006351, decoder SINDy loss  ratio: 0.004832\n",
      "Epoch 100\n",
      "   training loss 4.007515963166952e-05, (3.5480116e-06, 0.049344383, 0.068119854, 7.696224e-06)\n",
      "   validation loss 9.214694000547752e-05, (4.0197516e-05, 0.057347614, 0.09816408, 7.696224e-06)\n",
      "decoder loss ratio: 0.004792, decoder SINDy loss  ratio: 0.005248\n",
      "Epoch 200\n",
      "   training loss 4.052921212860383e-05, (3.6501076e-06, 0.049311336, 0.06882707, 7.696224e-06)\n",
      "   validation loss 8.399625949095935e-05, (3.1938478e-05, 0.055681877, 0.09854737, 7.696224e-06)\n",
      "decoder loss ratio: 0.003808, decoder SINDy loss  ratio: 0.005268\n",
      "Epoch 300\n",
      "   training loss 3.7639863876393065e-05, (3.0724912e-06, 0.049331963, 0.06420155, 7.696224e-06)\n",
      "   validation loss 7.428001845255494e-05, (2.6810698e-05, 0.05460702, 0.089477934, 7.696224e-06)\n",
      "decoder loss ratio: 0.003196, decoder SINDy loss  ratio: 0.004783\n",
      "Epoch 400\n",
      "   training loss 3.80326273443643e-05, (3.0435199e-06, 0.04933812, 0.0650444, 7.696224e-06)\n",
      "   validation loss 7.131227903300896e-05, (2.3889728e-05, 0.05401118, 0.08944398, 7.696224e-06)\n",
      "decoder loss ratio: 0.002848, decoder SINDy loss  ratio: 0.004782\n",
      "Epoch 500\n",
      "   training loss 3.928079968318343e-05, (3.2875562e-06, 0.04936479, 0.06705, 7.696224e-06)\n",
      "   validation loss 7.079793431330472e-05, (2.2163416e-05, 0.053755995, 0.09189344, 7.696224e-06)\n",
      "decoder loss ratio: 0.002642, decoder SINDy loss  ratio: 0.004913\n",
      "Epoch 600\n",
      "   training loss 3.663136885734275e-05, (2.7878464e-06, 0.04944394, 0.06274264, 7.696224e-06)\n",
      "   validation loss 6.532230327138677e-05, (2.0689415e-05, 0.053677186, 0.08389806, 7.696224e-06)\n",
      "decoder loss ratio: 0.002467, decoder SINDy loss  ratio: 0.004485\n",
      "Epoch 700\n",
      "   training loss 4.086937042302452e-05, (3.6372921e-06, 0.049487557, 0.0695154, 7.696224e-06)\n",
      "   validation loss 6.982599006732926e-05, (2.0086052e-05, 0.053674772, 0.094112396, 7.696224e-06)\n",
      "decoder loss ratio: 0.002395, decoder SINDy loss  ratio: 0.005031\n",
      "Epoch 800\n",
      "   training loss 3.549280154402368e-05, (2.54875e-06, 0.049621955, 0.060925905, 7.696224e-06)\n",
      "   validation loss 6.1030736105749384e-05, (1.8812962e-05, 0.053710155, 0.07906453, 7.696224e-06)\n",
      "decoder loss ratio: 0.002243, decoder SINDy loss  ratio: 0.004227\n",
      "Epoch 900\n",
      "   training loss 3.9297745388466865e-05, (3.2862113e-06, 0.04967342, 0.067055725, 7.696224e-06)\n",
      "   validation loss 6.365686567733064e-05, (1.8083912e-05, 0.053878613, 0.08575804, 7.696224e-06)\n",
      "decoder loss ratio: 0.002156, decoder SINDy loss  ratio: 0.004585\n",
      "Epoch 1000\n",
      "   training loss 3.840040517388843e-05, (3.086056e-06, 0.04975716, 0.06565298, 7.696224e-06)\n",
      "   validation loss 6.004715760354884e-05, (1.697236e-05, 0.054090273, 0.08074056, 7.696224e-06)\n",
      "decoder loss ratio: 0.002023, decoder SINDy loss  ratio: 0.004316\n",
      "EXPERIMENT 3\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.013045720756053925, (0.007933647, 0.08427715, 10.195772, 0.99729794)\n",
      "   validation loss 0.017567342147231102, (0.00820014, 0.08492248, 18.705967, 0.99729794)\n",
      "decoder loss ratio: 0.977629, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.012327260337769985, (0.0072236466, 7.2846096e-06, 10.195771, 0.5726292)\n",
      "   validation loss 0.01687800884246826, (0.007519297, 2.7288013e-05, 18.705967, 0.5726292)\n",
      "decoder loss ratio: 0.896459, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.012325460091233253, (0.007226672, 2.4867137e-05, 10.195771, 0.090025105)\n",
      "   validation loss 0.01686066947877407, (0.0075067817, 6.566876e-05, 18.705967, 0.090025105)\n",
      "decoder loss ratio: 0.894967, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.012325460091233253, (0.0072275707, 6.7902474e-05, 10.195771, 1.2759025e-05)\n",
      "   validation loss 0.01685771718621254, (0.007504725, 0.00016966293, 18.705967, 1.2759025e-05)\n",
      "decoder loss ratio: 0.894721, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.012325684539973736, (0.00722779, 0.00017215703, 10.195771, 3.2130134e-05)\n",
      "   validation loss 0.016857080161571503, (0.007504073, 0.000460458, 18.705967, 3.2130134e-05)\n",
      "decoder loss ratio: 0.894644, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.012325724586844444, (0.007227817, 0.00041566725, 10.195771, 3.2335363e-05)\n",
      "   validation loss 0.016856737434864044, (0.0075036944, 0.0011603592, 18.705967, 3.2335363e-05)\n",
      "decoder loss ratio: 0.894599, decoder SINDy loss  ratio: 1.000000\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.012325594201683998, (0.0072276504, 0.0011488779, 10.195771, 1.1227107e-05)\n",
      "   validation loss 0.016856348142027855, (0.007503199, 0.0032994072, 18.705967, 1.1227107e-05)\n",
      "decoder loss ratio: 0.894539, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 700\n",
      "   training loss 0.012324754148721695, (0.007226609, 0.005203721, 10.19577, 8.592865e-06)\n",
      "   validation loss 0.016854876652359962, (0.0075011696, 0.014461554, 18.705967, 8.592865e-06)\n",
      "decoder loss ratio: 0.894298, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 800\n",
      "   training loss 0.011841187253594398, (0.0066737193, 1.3936404, 10.195571, 1.04537285e-05)\n",
      "   validation loss 0.016316279768943787, (0.0068623214, 2.0251904, 18.705395, 1.04537285e-05)\n",
      "decoder loss ratio: 0.818133, decoder SINDy loss  ratio: 0.999969\n",
      "Epoch 900\n",
      "   training loss 0.010630501434206963, (0.0054677892, 1.5355537, 10.171868, 1.1951467e-05)\n",
      "   validation loss 0.015466384589672089, (0.006035177, 1.9256124, 18.669853, 1.1951467e-05)\n",
      "decoder loss ratio: 0.719520, decoder SINDy loss  ratio: 0.998069\n",
      "Epoch 1000\n",
      "   training loss 0.006993111222982407, (0.0034387168, 4.0547967, 6.7033095, 9.3112685e-06)\n",
      "   validation loss 0.01165417768061161, (0.0045886612, 4.797158, 13.651316, 9.3112685e-06)\n",
      "decoder loss ratio: 0.547065, decoder SINDy loss  ratio: 0.729784\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.0035320681054145098, (0.002114723, 2.113519, 2.6233377, 1.1754918e-05)\n",
      "   validation loss 0.007778773084282875, (0.0036697593, 3.5580351, 7.862224, 1.1754918e-05)\n",
      "decoder loss ratio: 0.437513, decoder SINDy loss  ratio: 0.420306\n",
      "Epoch 1200\n",
      "   training loss 0.0019474102882668376, (0.0013175656, 1.0503144, 1.1546576, 1.0209217e-05)\n",
      "   validation loss 0.005492042750120163, (0.002841863, 2.2352407, 5.0768356, 1.0209217e-05)\n",
      "decoder loss ratio: 0.338810, decoder SINDy loss  ratio: 0.271402\n",
      "Epoch 1300\n",
      "   training loss 0.0012100528692826629, (0.0009248003, 0.6334709, 0.50715774, 1.1677565e-05)\n",
      "   validation loss 0.004007499199360609, (0.0022924943, 1.4683015, 3.2831798, 1.1677565e-05)\n",
      "decoder loss ratio: 0.273314, decoder SINDy loss  ratio: 0.175515\n",
      "Epoch 1400\n",
      "   training loss 0.0007753416430205107, (0.0006329753, 0.46238285, 0.23849407, 1.2734509e-05)\n",
      "   validation loss 0.003063735319301486, (0.0018675649, 1.1128945, 2.281051, 1.2734509e-05)\n",
      "decoder loss ratio: 0.222653, decoder SINDy loss  ratio: 0.121942\n",
      "Epoch 1500\n",
      "   training loss 0.00037885288475081325, (0.00029799057, 0.36066055, 0.1256584, 7.481338e-06)\n",
      "   validation loss 0.0023143249563872814, (0.0014863913, 1.0692812, 1.548939, 7.481338e-06)\n",
      "decoder loss ratio: 0.177209, decoder SINDy loss  ratio: 0.082805\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 0.00013526456314139068, (7.996286e-05, 0.2699514, 0.08360808, 8.231425e-06)\n",
      "   validation loss 0.0017108992906287313, (0.0011552429, 0.80990154, 1.0303223, 8.231425e-06)\n",
      "decoder loss ratio: 0.137729, decoder SINDy loss  ratio: 0.055080\n",
      "Epoch 1700\n",
      "   training loss 7.431171979987994e-05, (2.5058771e-05, 0.2219555, 0.07631016, 9.130598e-06)\n",
      "   validation loss 0.0013102046214044094, (0.0009244055, 0.6260774, 0.7089902, 9.130598e-06)\n",
      "decoder loss ratio: 0.110209, decoder SINDy loss  ratio: 0.037902\n",
      "Epoch 1800\n",
      "   training loss 6.588529504369944e-05, (1.768416e-05, 0.19956882, 0.07644516, 1.1248088e-05)\n",
      "   validation loss 0.00104644859675318, (0.00077129813, 0.5197771, 0.4983229, 1.1248088e-05)\n",
      "decoder loss ratio: 0.091955, decoder SINDy loss  ratio: 0.026640\n",
      "Epoch 1900\n",
      "   training loss 5.745491944253445e-05, (1.1032009e-05, 0.1855362, 0.07429198, 1.0478987e-05)\n",
      "   validation loss 0.0008055833750404418, (0.0006065112, 0.4880232, 0.34934172, 1.0478987e-05)\n",
      "decoder loss ratio: 0.072309, decoder SINDy loss  ratio: 0.018675\n",
      "Epoch 2000\n",
      "   training loss 5.5152951972559094e-05, (9.646141e-06, 0.17839818, 0.07317356, 1.182924e-05)\n",
      "   validation loss 0.0006266380660235882, (0.00047101078, 0.41974527, 0.26927987, 1.182924e-05)\n",
      "decoder loss ratio: 0.056154, decoder SINDy loss  ratio: 0.014395\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 5.4967793403193355e-05, (9.885532e-06, 0.175064, 0.07265793, 9.56396e-06)\n",
      "   validation loss 0.0005190186202526093, (0.00038617855, 0.36285964, 0.22939388, 9.56396e-06)\n",
      "decoder loss ratio: 0.046041, decoder SINDy loss  ratio: 0.012263\n",
      "Epoch 2200\n",
      "   training loss 5.4699889005860314e-05, (9.572717e-06, 0.17292319, 0.07296178, 1.2111118e-05)\n",
      "   validation loss 0.0004450995766092092, (0.000329028, 0.32808644, 0.1993343, 1.2111118e-05)\n",
      "decoder loss ratio: 0.039227, decoder SINDy loss  ratio: 0.010656\n",
      "Epoch 2300\n",
      "   training loss 5.211666211835109e-05, (8.494799e-06, 0.17102554, 0.07014095, 1.1189804e-05)\n",
      "   validation loss 0.000386689294828102, (0.00028594804, 0.30618116, 0.17086416, 1.1189804e-05)\n",
      "decoder loss ratio: 0.034091, decoder SINDy loss  ratio: 0.009134\n",
      "Epoch 2400\n",
      "   training loss 5.566325853578746e-05, (7.788312e-06, 0.16968301, 0.07878143, 8.015314e-06)\n",
      "   validation loss 0.00034598360070958734, (0.00025050424, 0.2911784, 0.16184068, 8.015314e-06)\n",
      "decoder loss ratio: 0.029865, decoder SINDy loss  ratio: 0.008652\n",
      "Epoch 2500\n",
      "   training loss 5.472802877193317e-05, (7.0057135e-06, 0.16868368, 0.078576095, 8.103204e-06)\n",
      "   validation loss 0.00030614170827902853, (0.000219247, 0.27715898, 0.14607331, 8.103204e-06)\n",
      "decoder loss ratio: 0.026139, decoder SINDy loss  ratio: 0.007809\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 5.3877720347372815e-05, (6.3374964e-06, 0.16790928, 0.07828937, 7.626221e-06)\n",
      "   validation loss 0.0002717101888265461, (0.00019168836, 0.26184085, 0.13385943, 7.626221e-06)\n",
      "decoder loss ratio: 0.022853, decoder SINDy loss  ratio: 0.007156\n",
      "Epoch 2700\n",
      "   training loss 5.3117684728931636e-05, (5.777582e-06, 0.16738598, 0.0779414, 1.0299048e-05)\n",
      "   validation loss 0.000241939997067675, (0.00016737242, 0.24640578, 0.12449437, 1.0299048e-05)\n",
      "decoder loss ratio: 0.019954, decoder SINDy loss  ratio: 0.006655\n",
      "Epoch 2800\n",
      "   training loss 5.2458784921327606e-05, (5.3176204e-06, 0.16708484, 0.077573635, 1.0157328e-05)\n",
      "   validation loss 0.00021710536384489387, (0.00014686924, 0.23235086, 0.11723699, 1.0157328e-05)\n",
      "decoder loss ratio: 0.017510, decoder SINDy loss  ratio: 0.006267\n",
      "Epoch 2900\n",
      "   training loss 5.191584932617843e-05, (4.9638275e-06, 0.16689575, 0.07721427, 9.7532175e-06)\n",
      "   validation loss 0.00019693633657880127, (0.00013016372, 0.22191158, 0.11135387, 9.7532175e-06)\n",
      "decoder loss ratio: 0.015518, decoder SINDy loss  ratio: 0.005953\n",
      "Epoch 3000\n",
      "   training loss 5.148301715962589e-05, (4.6901664e-06, 0.16666116, 0.07691938, 1.03556995e-05)\n",
      "   validation loss 0.00017990377091336995, (0.00011613354, 0.21613409, 0.10592685, 1.03556995e-05)\n",
      "decoder loss ratio: 0.013846, decoder SINDy loss  ratio: 0.005663\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 5.113751467433758e-05, (4.4717553e-06, 0.16626148, 0.076705195, 8.780422e-06)\n",
      "   validation loss 0.00016453038551844656, (0.00010374845, 0.21318154, 0.10024556, 8.780422e-06)\n",
      "decoder loss ratio: 0.012369, decoder SINDy loss  ratio: 0.005359\n",
      "Epoch 3200\n",
      "   training loss 5.081933704786934e-05, (4.2479037e-06, 0.165685, 0.07657411, 1.2901179e-05)\n",
      "   validation loss 0.0001502058730693534, (9.2504655e-05, 0.21029288, 0.09437288, 1.2901179e-05)\n",
      "decoder loss ratio: 0.011029, decoder SINDy loss  ratio: 0.005045\n",
      "Epoch 3300\n",
      "   training loss 5.054170833318494e-05, (4.055024e-06, 0.16501068, 0.07647203, 1.3323673e-05)\n",
      "   validation loss 0.0001367850782116875, (8.214091e-05, 0.2060667, 0.08868141, 1.3323673e-05)\n",
      "decoder loss ratio: 0.009793, decoder SINDy loss  ratio: 0.004741\n",
      "Epoch 3400\n",
      "   training loss 5.026853978051804e-05, (3.874135e-06, 0.16436133, 0.07635249, 8.975259e-06)\n",
      "   validation loss 0.00012456013064365834, (7.271625e-05, 0.19968182, 0.083719395, 8.975259e-06)\n",
      "decoder loss ratio: 0.008669, decoder SINDy loss  ratio: 0.004476\n",
      "Epoch 3500\n",
      "   training loss 4.99660600326024e-05, (3.6845843e-06, 0.16384748, 0.07617802, 9.191241e-06)\n",
      "   validation loss 0.00011395899491617456, (6.441789e-05, 0.19182776, 0.07989926, 9.191241e-06)\n",
      "decoder loss ratio: 0.007680, decoder SINDy loss  ratio: 0.004271\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 4.9675494665279984e-05, (3.5180408e-06, 0.1634951, 0.07596517, 1.1267734e-05)\n",
      "   validation loss 0.00010492945148143917, (5.716489e-05, 0.18402371, 0.07712653, 1.1267734e-05)\n",
      "decoder loss ratio: 0.006815, decoder SINDy loss  ratio: 0.004123\n",
      "Epoch 3700\n",
      "   training loss 4.93739171361085e-05, (3.3429915e-06, 0.16328897, 0.07573274, 1.0494248e-05)\n",
      "   validation loss 9.725750715006143e-05, (5.0864408e-05, 0.17728736, 0.07505725, 1.0494248e-05)\n",
      "decoder loss ratio: 0.006064, decoder SINDy loss  ratio: 0.004012\n",
      "Epoch 3800\n",
      "   training loss 4.908828850602731e-05, (3.1731763e-06, 0.16317056, 0.07551293, 1.1706969e-05)\n",
      "   validation loss 9.068795770872384e-05, (4.5378805e-05, 0.17218241, 0.07339983, 1.1706969e-05)\n",
      "decoder loss ratio: 0.005410, decoder SINDy loss  ratio: 0.003924\n",
      "Epoch 3900\n",
      "   training loss 4.8841218813322484e-05, (3.0221238e-06, 0.16306937, 0.07533105, 1.010381e-05)\n",
      "   validation loss 8.487774175591767e-05, (4.0487732e-05, 0.16874969, 0.07190485, 1.010381e-05)\n",
      "decoder loss ratio: 0.004827, decoder SINDy loss  ratio: 0.003844\n",
      "Epoch 4000\n",
      "   training loss 4.863324647885747e-05, (2.895044e-06, 0.16294345, 0.07518182, 1.2033299e-05)\n",
      "   validation loss 7.967615238158032e-05, (3.609231e-05, 0.16646422, 0.07052101, 1.2033299e-05)\n",
      "decoder loss ratio: 0.004303, decoder SINDy loss  ratio: 0.003770\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 4.8379661166109145e-05, (2.7329313e-06, 0.16276534, 0.07501671, 1.0856249e-05)\n",
      "   validation loss 7.477719918824732e-05, (3.2130287e-05, 0.16484241, 0.06880936, 1.0856249e-05)\n",
      "decoder loss ratio: 0.003831, decoder SINDy loss  ratio: 0.003678\n",
      "Epoch 4200\n",
      "   training loss 4.763435208587907e-05, (2.3257319e-06, 0.16252185, 0.074364774, 1.4077821e-05)\n",
      "   validation loss 6.875850522192195e-05, (2.8455019e-05, 0.16360757, 0.06424593, 1.4077821e-05)\n",
      "decoder loss ratio: 0.003392, decoder SINDy loss  ratio: 0.003435\n",
      "Epoch 4300\n",
      "   training loss 4.732788875116967e-05, (2.185154e-06, 0.16223913, 0.0740613, 1.2612453e-05)\n",
      "   validation loss 6.443763413699344e-05, (2.5296184e-05, 0.16243689, 0.062038966, 1.2612453e-05)\n",
      "decoder loss ratio: 0.003016, decoder SINDy loss  ratio: 0.003317\n",
      "Epoch 4400\n",
      "   training loss 4.706270919996314e-05, (2.0692773e-06, 0.16190667, 0.07379598, 1.0708461e-05)\n",
      "   validation loss 6.06017310929019e-05, (2.2485985e-05, 0.16124639, 0.060106643, 1.0708461e-05)\n",
      "decoder loss ratio: 0.002681, decoder SINDy loss  ratio: 0.003213\n",
      "Epoch 4500\n",
      "   training loss 4.6829907660139725e-05, (1.9815018e-06, 0.16153818, 0.07354284, 7.3250844e-06)\n",
      "   validation loss 5.71381751797162e-05, (1.9985388e-05, 0.15997937, 0.058307488, 7.3250844e-06)\n",
      "decoder loss ratio: 0.002383, decoder SINDy loss  ratio: 0.003117\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 4.6613764425273985e-05, (1.8966342e-06, 0.1611265, 0.07332142, 9.913084e-06)\n",
      "   validation loss 5.398440407589078e-05, (1.7787455e-05, 0.1587225, 0.05652145, 9.913084e-06)\n",
      "decoder loss ratio: 0.002121, decoder SINDy loss  ratio: 0.003022\n",
      "Epoch 4700\n",
      "   training loss 4.645322042051703e-05, (1.8380232e-06, 0.16069779, 0.07316038, 1.1504647e-05)\n",
      "   validation loss 5.1168030040571466e-05, (1.5877102e-05, 0.15750994, 0.05483063, 1.1504647e-05)\n",
      "decoder loss ratio: 0.001893, decoder SINDy loss  ratio: 0.002931\n",
      "Epoch 4800\n",
      "   training loss 4.655322481994517e-05, (1.831091e-06, 0.16026749, 0.07341735, 8.451923e-06)\n",
      "   validation loss 4.879924745182507e-05, (1.427084e-05, 0.1564344, 0.053413205, 8.451923e-06)\n",
      "decoder loss ratio: 0.001701, decoder SINDy loss  ratio: 0.002855\n",
      "Epoch 4900\n",
      "   training loss 5.040146425017156e-05, (2.8842192e-06, 0.15992863, 0.07904142, 9.695142e-06)\n",
      "   validation loss 5.144594615558162e-05, (1.3730934e-05, 0.15556149, 0.059873678, 9.695142e-06)\n",
      "decoder loss ratio: 0.001637, decoder SINDy loss  ratio: 0.003201\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 4.544969124253839e-05, (8.8725324e-07, 0.159331, 0.07319177, 1.1033352e-05)\n",
      "   validation loss 4.375178468762897e-05, (1.11895615e-05, 0.15423882, 0.049700562, 1.1033352e-05)\n",
      "decoder loss ratio: 0.001334, decoder SINDy loss  ratio: 0.002657\n",
      "Epoch 100\n",
      "   training loss 6.378362741088495e-05, (5.989382e-06, 0.15947053, 0.099641435, 1.1033352e-05)\n",
      "   validation loss 7.596361683681607e-05, (1.318929e-05, 0.15339944, 0.110208705, 1.1033352e-05)\n",
      "decoder loss ratio: 0.001572, decoder SINDy loss  ratio: 0.005892\n",
      "Epoch 200\n",
      "   training loss 5.076667730463669e-05, (2.9595587e-06, 0.15891181, 0.07972305, 1.1033352e-05)\n",
      "   validation loss 5.344035889720544e-05, (1.0328018e-05, 0.15254852, 0.07096983, 1.1033352e-05)\n",
      "decoder loss ratio: 0.001231, decoder SINDy loss  ratio: 0.003794\n",
      "Epoch 300\n",
      "   training loss 4.9225884140469134e-05, (2.3979471e-06, 0.15841122, 0.07781475, 1.1033352e-05)\n",
      "   validation loss 4.932007141178474e-05, (9.276516e-06, 0.15180324, 0.06490678, 1.1033352e-05)\n",
      "decoder loss ratio: 0.001106, decoder SINDy loss  ratio: 0.003470\n",
      "Epoch 400\n",
      "   training loss 5.8073266700375825e-05, (4.2760958e-06, 0.15837976, 0.09175636, 1.1033352e-05)\n",
      "   validation loss 6.300571840256453e-05, (9.919053e-06, 0.15132856, 0.09104048, 1.1033352e-05)\n",
      "decoder loss ratio: 0.001183, decoder SINDy loss  ratio: 0.004867\n",
      "Epoch 500\n",
      "   training loss 6.990585825406015e-05, (6.8562927e-06, 0.15784605, 0.11031452, 1.1033352e-05)\n",
      "   validation loss 8.16093452158384e-05, (1.1203863e-05, 0.15051058, 0.1257599, 1.1033352e-05)\n",
      "decoder loss ratio: 0.001336, decoder SINDy loss  ratio: 0.006723\n",
      "Epoch 600\n",
      "   training loss 5.083620271761902e-05, (2.8237782e-06, 0.15715484, 0.08030936, 1.1033352e-05)\n",
      "   validation loss 5.037235314375721e-05, (7.907434e-06, 0.14977036, 0.0699528, 1.1033352e-05)\n",
      "decoder loss ratio: 0.000943, decoder SINDy loss  ratio: 0.003740\n",
      "Epoch 700\n",
      "   training loss 5.147428601048887e-05, (2.7774684e-06, 0.15672345, 0.08172128, 1.1033352e-05)\n",
      "   validation loss 5.0559967348817736e-05, (7.497362e-06, 0.14926144, 0.07119906, 1.1033352e-05)\n",
      "decoder loss ratio: 0.000894, decoder SINDy loss  ratio: 0.003806\n",
      "Epoch 800\n",
      "   training loss 4.606540096574463e-05, (1.6563016e-06, 0.15618175, 0.073200025, 1.1033352e-05)\n",
      "   validation loss 4.001882916782051e-05, (6.4563155e-06, 0.14873634, 0.052251395, 1.1033352e-05)\n",
      "decoder loss ratio: 0.000770, decoder SINDy loss  ratio: 0.002793\n",
      "Epoch 900\n",
      "   training loss 4.591982360580005e-05, (1.630621e-06, 0.15564474, 0.073013924, 1.1033352e-05)\n",
      "   validation loss 3.9354323234874755e-05, (6.1521077e-06, 0.1481663, 0.051587794, 1.1033352e-05)\n",
      "decoder loss ratio: 0.000733, decoder SINDy loss  ratio: 0.002758\n",
      "Epoch 1000\n",
      "   training loss 5.289854743750766e-05, (3.193098e-06, 0.15512751, 0.08389815, 1.1033352e-05)\n",
      "   validation loss 5.214504199102521e-05, (6.8599984e-06, 0.14740185, 0.0758299, 1.1033352e-05)\n",
      "decoder loss ratio: 0.000818, decoder SINDy loss  ratio: 0.004054\n",
      "EXPERIMENT 4\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.012882034294307232, (0.007772978, 0.023916893, 10.195771, 0.9974315)\n",
      "   validation loss 0.01749430038034916, (0.00813013, 0.024259057, 18.705967, 0.9974315)\n",
      "decoder loss ratio: 0.969283, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.01232769712805748, (0.007224138, 7.4237923e-06, 10.195771, 0.5673078)\n",
      "   validation loss 0.016878969967365265, (0.007520313, 1.2654405e-05, 18.705967, 0.5673078)\n",
      "decoder loss ratio: 0.896580, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.012325298972427845, (0.0072264634, 7.1602655e-05, 10.195771, 0.09453216)\n",
      "   validation loss 0.0168609619140625, (0.0075070215, 0.00022268647, 18.705967, 0.09453216)\n",
      "decoder loss ratio: 0.894995, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.012325286865234375, (0.0072273905, 0.00019640457, 10.195771, 1.5409858e-05)\n",
      "   validation loss 0.016857720911502838, (0.0075047095, 0.00054492295, 18.705967, 1.5409858e-05)\n",
      "decoder loss ratio: 0.894720, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.012325533665716648, (0.0072276234, 0.0004863909, 10.195771, 3.3225628e-05)\n",
      "   validation loss 0.016857005655765533, (0.0075039514, 0.0013962871, 18.705967, 3.3225628e-05)\n",
      "decoder loss ratio: 0.894629, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.012325463816523552, (0.007227515, 0.0012706378, 10.195771, 3.669766e-05)\n",
      "   validation loss 0.016856476664543152, (0.007503305, 0.0037343886, 18.705967, 3.669766e-05)\n",
      "decoder loss ratio: 0.894552, decoder SINDy loss  ratio: 1.000000\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.012324279174208641, (0.0072260527, 0.0067942906, 10.195771, 1.2526994e-05)\n",
      "   validation loss 0.016854479908943176, (0.0075005535, 0.018866876, 18.705967, 1.2526994e-05)\n",
      "decoder loss ratio: 0.894224, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 700\n",
      "   training loss 0.011761348694562912, (0.0065975767, 1.3211129, 10.195432, 1.1180401e-05)\n",
      "   validation loss 0.016242558136582375, (0.006802338, 1.7560946, 18.704828, 1.1180401e-05)\n",
      "decoder loss ratio: 0.810982, decoder SINDy loss  ratio: 0.999939\n",
      "Epoch 800\n",
      "   training loss 0.011098712682723999, (0.00598045, 0.4171259, 10.194811, 8.778713e-06)\n",
      "   validation loss 0.016018278896808624, (0.0066283885, 0.75244033, 18.704536, 8.778713e-06)\n",
      "decoder loss ratio: 0.790244, decoder SINDy loss  ratio: 0.999923\n",
      "Epoch 900\n",
      "   training loss 0.01098689530044794, (0.005875187, 0.29188702, 10.194227, 1.2324112e-05)\n",
      "   validation loss 0.01597200334072113, (0.0065944646, 0.5132761, 18.703749, 1.2324112e-05)\n",
      "decoder loss ratio: 0.786199, decoder SINDy loss  ratio: 0.999881\n",
      "Epoch 1000\n",
      "   training loss 0.010898680426180363, (0.005784431, 0.39558545, 10.188939, 9.773911e-06)\n",
      "   validation loss 0.015889480710029602, (0.0065022334, 0.7832993, 18.696163, 9.773911e-06)\n",
      "decoder loss ratio: 0.775203, decoder SINDy loss  ratio: 0.999476\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.009847533889114857, (0.0048475806, 2.3255014, 9.767356, 1.125311e-05)\n",
      "   validation loss 0.014848008751869202, (0.0055916645, 3.808984, 18.131788, 1.125311e-05)\n",
      "decoder loss ratio: 0.666644, decoder SINDy loss  ratio: 0.969305\n",
      "Epoch 1200\n",
      "   training loss 0.006792293395847082, (0.004308501, 3.1051497, 4.65707, 1.26075365e-05)\n",
      "   validation loss 0.010997026227414608, (0.005017322, 5.2613845, 11.4332695, 1.26075365e-05)\n",
      "decoder loss ratio: 0.598171, decoder SINDy loss  ratio: 0.611210\n",
      "Epoch 1300\n",
      "   training loss 0.0048411148600280285, (0.00347805, 1.7946972, 2.54666, 8.725138e-06)\n",
      "   validation loss 0.008630692958831787, (0.00434336, 3.3013012, 8.244534, 8.725138e-06)\n",
      "decoder loss ratio: 0.517820, decoder SINDy loss  ratio: 0.440743\n",
      "Epoch 1400\n",
      "   training loss 0.0024172256235033274, (0.0018902787, 0.88841844, 0.965052, 1.1195621e-05)\n",
      "   validation loss 0.005742786452174187, (0.0030704031, 2.2839978, 5.1163664, 1.1195621e-05)\n",
      "decoder loss ratio: 0.366057, decoder SINDy loss  ratio: 0.273515\n",
      "Epoch 1500\n",
      "   training loss 0.0013917358592152596, (0.0011509575, 0.56864697, 0.4246917, 1.2063279e-05)\n",
      "   validation loss 0.004394229035824537, (0.0025441602, 1.850004, 3.5151372, 1.2063279e-05)\n",
      "decoder loss ratio: 0.303318, decoder SINDy loss  ratio: 0.187915\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 0.0006993637653067708, (0.0005967469, 0.3609293, 0.16914053, 1.0649962e-05)\n",
      "   validation loss 0.0033135293051600456, (0.0021070887, 1.2604418, 2.2868369, 1.0649962e-05)\n",
      "decoder loss ratio: 0.251209, decoder SINDy loss  ratio: 0.122252\n",
      "Epoch 1700\n",
      "   training loss 0.0002915420336648822, (0.00023129741, 0.25996447, 0.094492644, 9.619513e-06)\n",
      "   validation loss 0.0026236651465296745, (0.0017973955, 0.820016, 1.5705374, 9.619513e-06)\n",
      "decoder loss ratio: 0.214287, decoder SINDy loss  ratio: 0.083959\n",
      "Epoch 1800\n",
      "   training loss 9.164141374640167e-05, (4.5376564e-05, 0.19920166, 0.072609305, 1.1912079e-05)\n",
      "   validation loss 0.0020262657199054956, (0.001478155, 0.549764, 1.0412446, 1.1912079e-05)\n",
      "decoder loss ratio: 0.176227, decoder SINDy loss  ratio: 0.055664\n",
      "Epoch 1900\n",
      "   training loss 5.87982103752438e-05, (1.621303e-05, 0.166107, 0.068559445, 1.0380577e-05)\n",
      "   validation loss 0.0015425228048115969, (0.0011930901, 0.4449914, 0.654366, 1.0380577e-05)\n",
      "decoder loss ratio: 0.142241, decoder SINDy loss  ratio: 0.034982\n",
      "Epoch 2000\n",
      "   training loss 5.256065560388379e-05, (1.0575376e-05, 0.14926802, 0.069043554, 1.0202374e-05)\n",
      "   validation loss 0.001209113048389554, (0.00095507293, 0.36922213, 0.4711578, 1.0202374e-05)\n",
      "decoder loss ratio: 0.113865, decoder SINDy loss  ratio: 0.025188\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 5.038120798417367e-05, (1.0385731e-05, 0.1372952, 0.06626115, 1.36876815e-05)\n",
      "   validation loss 0.0009144937503151596, (0.0007248679, 0.31858036, 0.34739345, 1.36876815e-05)\n",
      "decoder loss ratio: 0.086420, decoder SINDy loss  ratio: 0.018571\n",
      "Epoch 2200\n",
      "   training loss 4.942079249303788e-05, (9.632222e-06, 0.12893234, 0.06668375, 8.184822e-06)\n",
      "   validation loss 0.0007243223953992128, (0.0005783351, 0.28101605, 0.26387292, 8.184822e-06)\n",
      "decoder loss ratio: 0.068950, decoder SINDy loss  ratio: 0.014106\n",
      "Epoch 2300\n",
      "   training loss 4.846290539717302e-05, (8.287903e-06, 0.123417616, 0.06800803, 1.06668485e-05)\n",
      "   validation loss 0.0005922101554460824, (0.00047940892, 0.2560727, 0.19999497, 1.06668485e-05)\n",
      "decoder loss ratio: 0.057156, decoder SINDy loss  ratio: 0.010692\n",
      "Epoch 2400\n",
      "   training loss 4.791529136127792e-05, (7.1158156e-06, 0.11991708, 0.06960698, 1.29193895e-05)\n",
      "   validation loss 0.0004979996010661125, (0.00040483967, 0.22360933, 0.16395868, 1.29193895e-05)\n",
      "decoder loss ratio: 0.048265, decoder SINDy loss  ratio: 0.008765\n",
      "Epoch 2500\n",
      "   training loss 4.7960758820408955e-05, (6.274576e-06, 0.11744884, 0.071627274, 1.0225803e-05)\n",
      "   validation loss 0.0004328809736762196, (0.00034977953, 0.19216679, 0.14698596, 1.0225803e-05)\n",
      "decoder loss ratio: 0.041701, decoder SINDy loss  ratio: 0.007858\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 4.753410394187085e-05, (5.5587425e-06, 0.11534043, 0.07241648, 1.0222996e-05)\n",
      "   validation loss 0.0003836373216472566, (0.00030669305, 0.16930336, 0.13695794, 1.0222996e-05)\n",
      "decoder loss ratio: 0.036564, decoder SINDy loss  ratio: 0.007322\n",
      "Epoch 2700\n",
      "   training loss 4.6778182877460495e-05, (4.9029563e-06, 0.11350974, 0.07239926, 1.0885748e-05)\n",
      "   validation loss 0.000344633124768734, (0.00027243985, 0.15452139, 0.12893414, 1.0885748e-05)\n",
      "decoder loss ratio: 0.032481, decoder SINDy loss  ratio: 0.006893\n",
      "Epoch 2800\n",
      "   training loss 4.6170080167939886e-05, (4.401412e-06, 0.111881316, 0.072348975, 1.1448596e-05)\n",
      "   validation loss 0.0003118818858638406, (0.00024371012, 0.14653306, 0.12168997, 1.1448596e-05)\n",
      "decoder loss ratio: 0.029055, decoder SINDy loss  ratio: 0.006505\n",
      "Epoch 2900\n",
      "   training loss 4.568517397274263e-05, (4.0128475e-06, 0.11036866, 0.07230759, 9.658876e-06)\n",
      "   validation loss 0.0002814937033690512, (0.000217023, 0.14293227, 0.11464803, 9.658876e-06)\n",
      "decoder loss ratio: 0.025874, decoder SINDy loss  ratio: 0.006129\n",
      "Epoch 3000\n",
      "   training loss 4.5297114411368966e-05, (3.711608e-06, 0.108905815, 0.07228017, 1.3159821e-05)\n",
      "   validation loss 0.00025096992612816393, (0.00019015875, 0.14145145, 0.10747691, 1.3159821e-05)\n",
      "decoder loss ratio: 0.022671, decoder SINDy loss  ratio: 0.005746\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 4.4970867747906595e-05, (3.4816267e-06, 0.107520096, 0.072226286, 9.028806e-06)\n",
      "   validation loss 0.00022014406567905098, (0.00016309915, 0.13887276, 0.10020238, 9.028806e-06)\n",
      "decoder loss ratio: 0.019445, decoder SINDy loss  ratio: 0.005357\n",
      "Epoch 3200\n",
      "   training loss 4.4703174353344366e-05, (3.3366634e-06, 0.10627437, 0.07210538, 1.0244813e-05)\n",
      "   validation loss 0.0001903470401884988, (0.00013706961, 0.13426718, 0.09312794, 1.0244813e-05)\n",
      "decoder loss ratio: 0.016342, decoder SINDy loss  ratio: 0.004979\n",
      "Epoch 3300\n",
      "   training loss 4.4481053919298574e-05, (3.2395421e-06, 0.105209164, 0.071961835, 1.3538182e-05)\n",
      "   validation loss 0.0001629666076041758, (0.00011314811, 0.12854424, 0.08678231, 1.3538182e-05)\n",
      "decoder loss ratio: 0.013490, decoder SINDy loss  ratio: 0.004639\n",
      "Epoch 3400\n",
      "   training loss 4.425416045705788e-05, (3.153302e-06, 0.10432289, 0.071769245, 9.187345e-06)\n",
      "   validation loss 0.0001386416843160987, (9.182007e-05, 0.12257391, 0.08138566, 9.187345e-06)\n",
      "decoder loss ratio: 0.010947, decoder SINDy loss  ratio: 0.004351\n",
      "Epoch 3500\n",
      "   training loss 4.406031803227961e-05, (3.098582e-06, 0.10360604, 0.07156264, 1.1287831e-05)\n",
      "   validation loss 0.00011792135774157941, (7.350511e-05, 0.116967455, 0.07713552, 1.1287831e-05)\n",
      "decoder loss ratio: 0.008763, decoder SINDy loss  ratio: 0.004124\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 4.3901447497773916e-05, (3.0884385e-06, 0.10303401, 0.07132241, 1.0366653e-05)\n",
      "   validation loss 0.000100935016234871, (5.8382324e-05, 0.11219104, 0.07388608, 1.0366653e-05)\n",
      "decoder loss ratio: 0.006960, decoder SINDy loss  ratio: 0.003950\n",
      "Epoch 3700\n",
      "   training loss 4.375018033897504e-05, (3.0800813e-06, 0.102581635, 0.07108182, 1.0908608e-05)\n",
      "   validation loss 8.751412678975612e-05, (4.6324923e-05, 0.10838269, 0.071539916, 1.0908608e-05)\n",
      "decoder loss ratio: 0.005523, decoder SINDy loss  ratio: 0.003824\n",
      "Epoch 3800\n",
      "   training loss 4.3601532524917275e-05, (3.0733697e-06, 0.10222579, 0.070833534, 1.0499675e-05)\n",
      "   validation loss 7.724003808107227e-05, (3.703254e-05, 0.105463065, 0.06986849, 1.0499675e-05)\n",
      "decoder loss ratio: 0.004415, decoder SINDy loss  ratio: 0.003735\n",
      "Epoch 3900\n",
      "   training loss 4.3467571231303737e-05, (3.069827e-06, 0.10194682, 0.07060055, 1.2738693e-05)\n",
      "   validation loss 6.961208418942988e-05, (3.0119003e-05, 0.10321997, 0.068663895, 1.2738693e-05)\n",
      "decoder loss ratio: 0.003591, decoder SINDy loss  ratio: 0.003671\n",
      "Epoch 4000\n",
      "   training loss 4.33441782661248e-05, (3.0683073e-06, 0.101727515, 0.0703788, 9.613189e-06)\n",
      "   validation loss 6.40894504613243e-05, (2.5138603e-05, 0.10150038, 0.067751475, 9.613189e-06)\n",
      "decoder loss ratio: 0.002997, decoder SINDy loss  ratio: 0.003622\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 4.320655716583133e-05, (3.0504577e-06, 0.101553455, 0.07015666, 9.619743e-06)\n",
      "   validation loss 6.011414006934501e-05, (2.1595806e-05, 0.10021033, 0.06701545, 9.619743e-06)\n",
      "decoder loss ratio: 0.002575, decoder SINDy loss  ratio: 0.003583\n",
      "Epoch 4200\n",
      "   training loss 4.309268479119055e-05, (3.0405415e-06, 0.10141118, 0.06996291, 1.2906494e-05)\n",
      "   validation loss 5.728624455514364e-05, (1.9105144e-05, 0.099254414, 0.06643651, 1.2906494e-05)\n",
      "decoder loss ratio: 0.002278, decoder SINDy loss  ratio: 0.003552\n",
      "Epoch 4300\n",
      "   training loss 4.2985888285329565e-05, (3.033291e-06, 0.10128529, 0.06977649, 8.599601e-06)\n",
      "   validation loss 5.5213546147570014e-05, (1.7325332e-05, 0.09854246, 0.06592201, 8.599601e-06)\n",
      "decoder loss ratio: 0.002066, decoder SINDy loss  ratio: 0.003524\n",
      "Epoch 4400\n",
      "   training loss 4.28860257670749e-05, (3.0243148e-06, 0.10116179, 0.069607005, 1.2131098e-05)\n",
      "   validation loss 5.363133459468372e-05, (1.6002545e-05, 0.097987555, 0.06545858, 1.2131098e-05)\n",
      "decoder loss ratio: 0.001908, decoder SINDy loss  ratio: 0.003499\n",
      "Epoch 4500\n",
      "   training loss 4.2809122533071786e-05, (3.0235285e-06, 0.101026244, 0.06946834, 1.07801725e-05)\n",
      "   validation loss 5.236968718236312e-05, (1.4977606e-05, 0.09750121, 0.06503382, 1.07801725e-05)\n",
      "decoder loss ratio: 0.001786, decoder SINDy loss  ratio: 0.003477\n",
      "THRESHOLDING: 0 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 4.273362719686702e-05, (3.015458e-06, 0.10086452, 0.06934967, 1.0744068e-05)\n",
      "   validation loss 5.1280148909427226e-05, (1.41262035e-05, 0.097021304, 0.06460554, 1.0744068e-05)\n",
      "decoder loss ratio: 0.001684, decoder SINDy loss  ratio: 0.003454\n",
      "Epoch 4700\n",
      "   training loss 4.267030817572959e-05, (3.0174858e-06, 0.1006719, 0.06923817, 1.4208231e-05)\n",
      "   validation loss 5.030311513110064e-05, (1.3400985e-05, 0.09654769, 0.06414921, 1.4208231e-05)\n",
      "decoder loss ratio: 0.001598, decoder SINDy loss  ratio: 0.003429\n",
      "Epoch 4800\n",
      "   training loss 4.260241985321045e-05, (3.0045671e-06, 0.10045325, 0.06915014, 1.17118e-05)\n",
      "   validation loss 4.939545760862529e-05, (1.2728164e-05, 0.09609536, 0.06372482, 1.17118e-05)\n",
      "decoder loss ratio: 0.001517, decoder SINDy loss  ratio: 0.003407\n",
      "Epoch 4900\n",
      "   training loss 4.2557494452921674e-05, (3.006755e-06, 0.100214556, 0.06907982, 1.012709e-05)\n",
      "   validation loss 4.856244777329266e-05, (1.2113995e-05, 0.09565119, 0.063331574, 1.012709e-05)\n",
      "decoder loss ratio: 0.001444, decoder SINDy loss  ratio: 0.003386\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 4.361547325970605e-05, (9.993109e-07, 0.09913113, 0.07531921, 1.04793e-05)\n",
      "   validation loss 4.5070028136251494e-05, (1.0646563e-05, 0.095129974, 0.059333928, 1.04793e-05)\n",
      "decoder loss ratio: 0.001269, decoder SINDy loss  ratio: 0.003172\n",
      "Epoch 100\n",
      "   training loss 4.243911462253891e-05, (2.997277e-06, 0.099676594, 0.068916015, 1.04793e-05)\n",
      "   validation loss 4.693299706559628e-05, (1.0945783e-05, 0.094821736, 0.06249225, 1.04793e-05)\n",
      "decoder loss ratio: 0.001305, decoder SINDy loss  ratio: 0.003341\n",
      "Epoch 200\n",
      "   training loss 4.240349881001748e-05, (3.0078616e-06, 0.099391736, 0.0688521, 1.04793e-05)\n",
      "   validation loss 4.61312010884285e-05, (1.0379723e-05, 0.09438561, 0.062064394, 1.04793e-05)\n",
      "decoder loss ratio: 0.001237, decoder SINDy loss  ratio: 0.003318\n",
      "Epoch 300\n",
      "   training loss 4.2366893467260525e-05, (3.0138224e-06, 0.09909459, 0.06879668, 1.04793e-05)\n",
      "   validation loss 4.5328990381676704e-05, (9.817235e-06, 0.093954116, 0.061628103, 1.04793e-05)\n",
      "decoder loss ratio: 0.001170, decoder SINDy loss  ratio: 0.003295\n",
      "Epoch 400\n",
      "   training loss 4.230792910675518e-05, (3.0003434e-06, 0.09878625, 0.068736546, 1.04793e-05)\n",
      "   validation loss 4.4494736357592046e-05, (9.232711e-06, 0.09352539, 0.06117151, 1.04793e-05)\n",
      "decoder loss ratio: 0.001101, decoder SINDy loss  ratio: 0.003270\n",
      "Epoch 500\n",
      "   training loss 4.226480086799711e-05, (3.0041358e-06, 0.09846723, 0.0686746, 1.04793e-05)\n",
      "   validation loss 4.368045483715832e-05, (8.67575e-06, 0.0930963, 0.060699776, 1.04793e-05)\n",
      "decoder loss ratio: 0.001034, decoder SINDy loss  ratio: 0.003245\n",
      "Epoch 600\n",
      "   training loss 4.22192424593959e-05, (3.0058372e-06, 0.09814012, 0.06861279, 1.04793e-05)\n",
      "   validation loss 4.28720741183497e-05, (8.12427e-06, 0.09266584, 0.060229026, 1.04793e-05)\n",
      "decoder loss ratio: 0.000969, decoder SINDy loss  ratio: 0.003220\n",
      "Epoch 700\n",
      "   training loss 4.2176492570433766e-05, (3.0004255e-06, 0.09780792, 0.068571344, 1.04793e-05)\n",
      "   validation loss 4.209009057376534e-05, (7.576873e-06, 0.092234895, 0.059802942, 1.04793e-05)\n",
      "decoder loss ratio: 0.000903, decoder SINDy loss  ratio: 0.003197\n",
      "Epoch 800\n",
      "   training loss 4.2150262743234634e-05, (3.018057e-06, 0.09747224, 0.068517186, 1.04793e-05)\n",
      "   validation loss 4.135594645049423e-05, (7.0832507e-06, 0.09180363, 0.059365023, 1.04793e-05)\n",
      "decoder loss ratio: 0.000844, decoder SINDy loss  ratio: 0.003174\n",
      "Epoch 900\n",
      "   training loss 4.2079635022673756e-05, (2.9908986e-06, 0.09713649, 0.06846382, 1.04793e-05)\n",
      "   validation loss 4.061038634972647e-05, (6.5655986e-06, 0.09137599, 0.058951974, 1.04793e-05)\n",
      "decoder loss ratio: 0.000783, decoder SINDy loss  ratio: 0.003152\n",
      "Epoch 1000\n",
      "   training loss 4.204343713354319e-05, (3.0031583e-06, 0.09680255, 0.0684003, 1.04793e-05)\n",
      "   validation loss 3.995421502622776e-05, (6.134357e-06, 0.090957835, 0.05854393, 1.04793e-05)\n",
      "decoder loss ratio: 0.000731, decoder SINDy loss  ratio: 0.003130\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 5\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'pendulum_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = pd.concat([df, pd.DataFrame([{**results_dict, **params}])], ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
